"""
ç›®æ ‡æ ¼å¼è½¬æ¢å·¥å…·
å°†æ•°æ®é›†çš„æ ‡æ³¨æ ¼å¼è½¬æ¢ä¸ºæ¨¡å‹æŸå¤±å‡½æ•°éœ€è¦çš„æ ¼å¼
"""

import torch
import numpy as np
from typing import List, Dict, Optional


def convert_targets_for_loss(
    targets_batch: List[Dict],
    num_frames: int,
    img_size: int,
    feature_size: int,
    device: torch.device,
    use_tracking_offset: bool = False
) -> List[Dict]:
    """
    å°†æ•°æ®é›†æ ‡æ³¨è½¬æ¢ä¸ºæŸå¤±å‡½æ•°æ ¼å¼
    
    å‚æ•°ï¼š
        targets_batch: List[Dict]ï¼Œé•¿åº¦ä¸º Bï¼ˆbatch sizeï¼‰
            æ¯ä¸ª Dict åŒ…å« 'boxes' å’Œ 'labels'ï¼Œæ˜¯è¯¥æ ·æœ¬æ‰€æœ‰å¸§çš„æ ‡æ³¨
        num_frames: å¸§æ•° T
        img_size: åŸå§‹å›¾åƒå°ºå¯¸
        feature_size: ç‰¹å¾å›¾å°ºå¯¸
        device: è®¾å¤‡
        
    è¿”å›ï¼š
        frame_targets: List[Dict]ï¼Œé•¿åº¦ä¸º Tï¼ˆå¸§æ•°ï¼‰
            æ¯ä¸ª Dict åŒ…å«è¯¥å¸§æ‰€æœ‰æ ·æœ¬çš„æ ‡æ³¨
    """
    batch_size = len(targets_batch)
    stride = img_size / feature_size
    
    # åˆå§‹åŒ–æ¯å¸§çš„ç›®æ ‡
    frame_targets = []
    
    for t in range(num_frames):
        # ä¸ºè¯¥å¸§åˆ›å»ºæ‰¹æ¬¡çº§æ ‡æ³¨
        cls_maps = []
        bbox_maps = []
        valid_masks = []
        centerness_maps = []  # æ–°å¢
        
        for b in range(batch_size):
            target = targets_batch[b]
            boxes = target['boxes']  # List of [x1, y1, x2, y2] (normalized)
            labels = target['labels']  # List of category_id
            
            # åˆ›å»ºè¯¥æ ·æœ¬çš„åˆ†ç±»å’Œè¾¹ç•Œæ¡† map
            # ğŸ”¥ æ”¹è¿›v3: YOLOå¼æ­£è´Ÿæ ·æœ¬åˆ†é…
            # - ignore: -100 (è¿œç¦»ç›®æ ‡çš„åŒºåŸŸ)
            # - è´Ÿæ ·æœ¬: num_classes (èƒŒæ™¯ç±»ï¼Œç›®æ ‡å‘¨å›´åŒºåŸŸ)
            # - æ­£æ ·æœ¬: 0~num_classes-1 (å‰æ™¯ç±»ï¼Œç›®æ ‡ä¸­å¿ƒåŒºåŸŸ)
            cls_map = torch.full((feature_size, feature_size), -100, dtype=torch.long)
            bbox_map = torch.zeros(4, feature_size, feature_size, dtype=torch.float32)
            valid_mask = torch.zeros(feature_size, feature_size, dtype=torch.bool)
            centerness_map = torch.zeros(1, feature_size, feature_size, dtype=torch.float32)
            
            # éå†æ‰€æœ‰ç›®æ ‡
            for box, label in zip(boxes, labels):
                x1, y1, x2, y2 = box
                
                # è½¬æ¢ä¸ºç‰¹å¾å›¾åæ ‡
                x1_feat = x1 * feature_size
                y1_feat = y1 * feature_size
                x2_feat = x2 * feature_size
                y2_feat = y2 * feature_size
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                cx = (x1_feat + x2_feat) / 2
                cy = (y1_feat + y2_feat) / 2
                grid_x = int(cx)
                grid_y = int(cy)
                
                # ä»ä¸­å¿ƒç‚¹è®¡ç®—bboxï¼ˆä¿è¯l,t,r,béƒ½æ˜¯æ­£æ•°ï¼‰
                l = cx - x1_feat
                t = cy - y1_feat
                r = x2_feat - cx
                b = y2_feat - cy
                
                # è®¡ç®—centerness
                min_lr = min(l, r)
                max_lr = max(l, r) + 1e-6
                min_tb = min(t, b)
                max_tb = max(t, b) + 1e-6
                centerness = ((min_lr / max_lr) * (min_tb / max_tb)) ** 0.5
                
                # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šYOLOå¼æ­£è´Ÿæ ·æœ¬åŠå¾„
                # positive_radius: æ­£æ ·æœ¬åŒºåŸŸï¼ˆä¸­å¿ƒï¼‰
                # negative_radius: è´Ÿæ ·æœ¬åŒºåŸŸï¼ˆå‘¨å›´ï¼‰
                # ç›®æ ‡ï¼šæ­£è´Ÿæ¯”ä¾‹ 1:10~15
                box_size = max(x2_feat - x1_feat, y2_feat - y1_feat)
                if box_size < 2.0:  # è¶…å°ç›®æ ‡ï¼ˆ<16åƒç´ ï¼‰
                    positive_radius = 0  # ä¸­å¿ƒç‚¹
                    negative_radius = 4  # 9Ã—9è´Ÿæ ·æœ¬åŒºåŸŸ
                elif box_size < 4.0:  # å°ç›®æ ‡ï¼ˆ<32åƒç´ ï¼‰
                    positive_radius = 1  # 3Ã—3æ­£æ ·æœ¬
                    negative_radius = 5  # 11Ã—11è´Ÿæ ·æœ¬åŒºåŸŸ
                else:  # ä¸­å¤§ç›®æ ‡
                    positive_radius = 2  # 5Ã—5æ­£æ ·æœ¬
                    negative_radius = 7  # 15Ã—15è´Ÿæ ·æœ¬åŒºåŸŸ
                
                # æ­¥éª¤1: å…ˆæ ‡è®°è´Ÿæ ·æœ¬åŒºåŸŸï¼ˆèƒŒæ™¯ï¼‰
                # è¿™äº›ä½ç½®ä¼šå‚ä¸è®­ç»ƒï¼Œä½†æ ‡ç­¾ä¸ºèƒŒæ™¯ç±»
                for dy in range(-negative_radius, negative_radius + 1):
                    for dx in range(-negative_radius, negative_radius + 1):
                        px = grid_x + dx
                        py = grid_y + dy
                        
                        # è¾¹ç•Œæ£€æŸ¥
                        if 0 <= px < feature_size and 0 <= py < feature_size:
                            # åªæœ‰å½“å‰æ˜¯ignoreæ—¶æ‰æ ‡è®°ä¸ºèƒŒæ™¯
                            # ï¼ˆé¿å…è¦†ç›–å…¶ä»–ç›®æ ‡çš„æ­£æ ·æœ¬ï¼‰
                            if cls_map[py, px] == -100:
                                # num_classesæ˜¯èƒŒæ™¯ç±»çš„IDï¼ˆä¾‹å¦‚7ä¸ªç±»ï¼ŒèƒŒæ™¯æ˜¯ç¬¬8ç±»ï¼‰
                                # æ³¨æ„ï¼šéœ€è¦åœ¨æ¨¡å‹è¾“å‡ºå±‚æ·»åŠ ä¸€ä¸ªèƒŒæ™¯é€šé“
                                cls_map[py, px] = 7  # å‡è®¾æœ‰7ä¸ªå‰æ™¯ç±»ï¼ŒèƒŒæ™¯ç±»ID=7
                
                # æ­¥éª¤2: å†æ ‡è®°æ­£æ ·æœ¬åŒºåŸŸï¼ˆå‰æ™¯ï¼‰
                # è¿™ä¼šè¦†ç›–æ­¥éª¤1ä¸­å¿ƒåŒºåŸŸçš„èƒŒæ™¯æ ‡ç­¾
                # ğŸ”¥ğŸ”¥ğŸ”¥ ä¸¥é‡BUGä¿®å¤ï¼šæ¯ä¸ªç‚¹è®¡ç®—è‡ªå·±çš„ltrb
                for dy in range(-positive_radius, positive_radius + 1):
                    for dx in range(-positive_radius, positive_radius + 1):
                        px = grid_x + dx
                        py = grid_y + dy
                        
                        # è¾¹ç•Œæ£€æŸ¥
                        if 0 <= px < feature_size and 0 <= py < feature_size:
                            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¯ä¸ªç‚¹è®¡ç®—è‡ªå·±çš„ä¸­å¿ƒ
                            px_center = px + 0.5
                            py_center = py + 0.5
                            
                            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç›¸å¯¹äºè¯¥ç‚¹çš„ä¸­å¿ƒè®¡ç®—ltrb
                            l_point = px_center - x1_feat
                            t_point = py_center - y1_feat
                            r_point = x2_feat - px_center
                            b_point = y2_feat - py_center
                            
                            # ç¡®ä¿è¯¥ç‚¹åœ¨boxå†…éƒ¨ï¼ˆltrbéƒ½ä¸ºæ­£ï¼‰
                            if l_point > 0 and t_point > 0 and r_point > 0 and b_point > 0:
                                # è®¾ç½®å‰æ™¯ç±»æ ‡ç­¾
                                cls_map[py, px] = label
                                
                                # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨è¯¥ç‚¹è‡ªå·±çš„ltrb
                                bbox_map[0, py, px] = l_point
                                bbox_map[1, py, px] = t_point
                                bbox_map[2, py, px] = r_point
                                bbox_map[3, py, px] = b_point
                                
                                # ğŸ”¥ ä¿®å¤ï¼šé‡æ–°è®¡ç®—è¯¥ç‚¹çš„centerness
                                min_lr = min(l_point, r_point)
                                max_lr = max(l_point, r_point) + 1e-6
                                min_tb = min(t_point, b_point)
                                max_tb = max(t_point, b_point) + 1e-6
                                centerness_point = ((min_lr / max_lr) * (min_tb / max_tb)) ** 0.5
                                centerness_map[0, py, px] = centerness_point
                                
                                # è®¾ç½®æœ‰æ•ˆæ©ç 
                                valid_mask[py, px] = True
            
            cls_maps.append(cls_map)
            bbox_maps.append(bbox_map)
            valid_masks.append(valid_mask)
            centerness_maps.append(centerness_map)
        
        # å †å ä¸ºæ‰¹æ¬¡
        frame_target = {
            'cls': torch.stack(cls_maps, dim=0).to(device),  # (B, H, W)
            'bbox': torch.stack(bbox_maps, dim=0).to(device),  # (B, 4, H, W)
            'valid': torch.stack(valid_masks, dim=0).to(device),  # (B, H, W)
            'centerness': torch.stack(centerness_maps, dim=0).to(device)  # (B, 1, H, W)
        }
        
        frame_targets.append(frame_target)
    
    # è®¡ç®—offset targetï¼ˆç›¸é‚»å¸§ä¹‹é—´çš„åç§»ï¼‰
    for t in range(num_frames - 1):
        offset_maps = []
        
        for b in range(batch_size):
            offset_map = torch.zeros(2, feature_size, feature_size, dtype=torch.float32)
            
            target = targets_batch[b]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ tracking_id å’Œ offset_info
            if use_tracking_offset and 'frames_offsets' in target:
                # ä½¿ç”¨é¢„è®¡ç®—çš„ offset
                offset_info = target['frames_offsets'][t]
                offset_map = offset_info['offset_map'].clone()
            else:
                # ç®€åŒ–ç‰ˆæœ¬ï¼šç¡¬ç¼–ç ä¸º 0
                # å¦‚æœæ²¡æœ‰å¯ç”¨ tracking æˆ–æ²¡æœ‰ offset ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
                valid_mask_t = frame_targets[t]['valid'][b]  # (H, W)
                offset_map[0, valid_mask_t] = 0.0  # dx
                offset_map[1, valid_mask_t] = 0.0  # dy
            
            offset_maps.append(offset_map)
        
        # æ·»åŠ offsetåˆ°å½“å‰å¸§çš„target
        frame_targets[t]['offset'] = torch.stack(offset_maps, dim=0).to(device)  # (B, 2, H, W)
    
    # æœ€åä¸€å¸§æ²¡æœ‰offsetï¼ˆæ²¡æœ‰ä¸‹ä¸€å¸§ï¼‰
    # ä¸æ·»åŠ offsetå­—æ®µï¼Œåœ¨lossè®¡ç®—ä¸­ä¼šè¢«è·³è¿‡
    
    return frame_targets


def convert_targets_simple(
    targets_batch: List[Dict],
    num_frames: int,
    device: torch.device
) -> List[Dict]:
    """
    ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥å¤åˆ¶æ ‡æ³¨åˆ°æ¯ä¸€å¸§
    ï¼ˆå‡è®¾æ‰€æœ‰å¸§çš„æ ‡æ³¨ç›¸åŒï¼Œé€‚ç”¨äºé™æ€åœºæ™¯æˆ–åºåˆ—æ ‡æ³¨ï¼‰
    
    å‚æ•°ï¼š
        targets_batch: List[Dict]ï¼Œé•¿åº¦ä¸º B
        num_frames: å¸§æ•° T
        device: è®¾å¤‡
        
    è¿”å›ï¼š
        frame_targets: List[Dict]ï¼Œé•¿åº¦ä¸º T
    """
    frame_targets = []
    
    for t in range(num_frames):
        # æ¯å¸§ä½¿ç”¨ç›¸åŒçš„æ ‡æ³¨ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        frame_target = {
            'boxes_list': [],  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ boxes
            'labels_list': []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ labels
        }
        
        for target in targets_batch:
            frame_target['boxes_list'].append(target['boxes'])
            frame_target['labels_list'].append(target['labels'])
        
        frame_targets.append(frame_target)
    
    return frame_targets


if __name__ == "__main__":
    # æµ‹è¯•è½¬æ¢
    print("æµ‹è¯•ç›®æ ‡æ ¼å¼è½¬æ¢...")
    
    # æ¨¡æ‹Ÿæ•°æ®
    targets_batch = [
        {
            'boxes': [[0.1, 0.1, 0.3, 0.3], [0.5, 0.5, 0.7, 0.7]],
            'labels': [0, 1]
        },
        {
            'boxes': [[0.2, 0.2, 0.4, 0.4]],
            'labels': [2]
        }
    ]
    
    device = torch.device('cpu')
    frame_targets = convert_targets_for_loss(
        targets_batch,
        num_frames=5,
        img_size=640,
        feature_size=40,
        device=device
    )
    
    print(f"è½¬æ¢åå¸§æ•°: {len(frame_targets)}")
    print(f"ç¬¬ä¸€å¸§ cls shape: {frame_targets[0]['cls'].shape}")
    print(f"ç¬¬ä¸€å¸§ bbox shape: {frame_targets[0]['bbox'].shape}")
    print(f"ç¬¬ä¸€å¸§ valid shape: {frame_targets[0]['valid'].shape}")
    print(f"ç¬¬ä¸€å¸§æœ‰æ•ˆä½ç½®æ•°: {frame_targets[0]['valid'].sum().item()}")
    
    print("\nâœ“ ç›®æ ‡æ ¼å¼è½¬æ¢æµ‹è¯•é€šè¿‡ï¼")


