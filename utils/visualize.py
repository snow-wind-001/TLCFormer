"""
å¯è§†åŒ–å·¥å…·
ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯è§†åŒ–æ£€æµ‹ç»“æœ
"""

import torch
import numpy as np
import cv2
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from typing import List, Dict, Tuple
import io
from PIL import Image


def visualize_detection_results(
    rgb_frames: torch.Tensor,
    thermal_frames: torch.Tensor,
    predictions: List[Dict[str, torch.Tensor]],
    targets: List[Dict],
    class_names: List[str],
    score_thresh: float = 0.3,
    max_samples: int = 4,
    mid_frame_only: bool = True
) -> List[np.ndarray]:
    """
    å¯è§†åŒ–æ£€æµ‹ç»“æœ
    
    å‚æ•°ï¼š
        rgb_frames: (B, T, 3, H, W) RGBå¸§
        thermal_frames: (B, T, 1, H, W) çƒ­çº¢å¤–å¸§  
        predictions: List of dictï¼Œæ¨¡å‹é¢„æµ‹
        targets: List of dictï¼ŒçœŸå®æ ‡æ³¨
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        score_thresh: åˆ†æ•°é˜ˆå€¼
        max_samples: æœ€å¤šå¯è§†åŒ–æ ·æœ¬æ•°
        mid_frame_only: æ˜¯å¦åªå¯è§†åŒ–ä¸­é—´å¸§
        
    è¿”å›:
        vis_images: å¯è§†åŒ–å›¾åƒåˆ—è¡¨ï¼ˆnumpyæ•°ç»„ï¼ŒRGBæ ¼å¼ï¼‰
    """
    B, T, _, H, W = rgb_frames.shape
    mid_frame = T // 2 if mid_frame_only else 0
    
    vis_images = []
    num_samples = min(B, max_samples)
    
    for b in range(num_samples):
        # é€‰æ‹©è¦å¯è§†åŒ–çš„å¸§
        frame_idx = mid_frame
        
        # è·å–RGBå’ŒThermalå›¾åƒ
        rgb_img = rgb_frames[b, frame_idx].cpu().permute(1, 2, 0).numpy()
        thermal_img = thermal_frames[b, frame_idx, 0].cpu().numpy()
        
        # åå½’ä¸€åŒ–
        rgb_img = np.clip(rgb_img * 255, 0, 255).astype(np.uint8)
        thermal_img = np.clip(thermal_img * 255, 0, 255).astype(np.uint8)
        
        # ğŸ”¥ ä¿®å¤ï¼špredictionsæ˜¯List[Dict]ï¼Œæ¯ä¸ªdictçš„å½¢çŠ¶æ˜¯(B, C, H', W')
        # éœ€è¦æ ¹æ®frame_idxé€‰æ‹©å¯¹åº”çš„é¢„æµ‹
        if frame_idx < len(predictions):
            pred = predictions[frame_idx]
            cls_pred = pred['cls'][b]  # (num_classes+1, H', W')
            bbox_pred = pred['bbox'][b]  # (4, H', W')
            centerness_pred = pred.get('centerness', None)
            if centerness_pred is not None:
                centerness_pred = centerness_pred[b]  # (1, H', W')
            
            # ğŸ”¥ ä¿®å¤ï¼šæ’é™¤èƒŒæ™¯ç±»ï¼ˆæœ€åä¸€ä¸ªé€šé“ï¼‰
            # num_classesæ˜¯å‰æ™¯ç±»æ•°é‡ï¼Œæ¨¡å‹è¾“å‡ºæ˜¯num_classes+1
            num_fg_classes = cls_pred.shape[0] - 1  # 7ä¸ªå‰æ™¯ç±»
            cls_pred_fg = cls_pred[:num_fg_classes]  # åªå–å‰7ä¸ªé€šé“
            
            # è§£ç é¢„æµ‹ï¼ˆæ·»åŠ centernessï¼‰
            pred_boxes, pred_scores, pred_labels = decode_predictions(
                cls_pred_fg, bbox_pred, centerness_pred, H, W, score_thresh
            )
        else:
            # å¦‚æœframe_idxè¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç©ºé¢„æµ‹
            pred_boxes = np.zeros((0, 4))
            pred_scores = np.zeros(0)
            pred_labels = np.zeros(0, dtype=np.int64)
        
        # è·å–GT
        if b < len(targets):
            target = targets[b]
            gt_boxes_norm = target.get('boxes', [])  # å½’ä¸€åŒ–åæ ‡ [x1, y1, x2, y2]
            gt_labels = target.get('labels', [])
            
            # ğŸ”¥ ä¿®å¤ï¼šå°†å½’ä¸€åŒ–çš„GT boxesè½¬æ¢ä¸ºåƒç´ åæ ‡
            if isinstance(gt_boxes_norm, torch.Tensor) and len(gt_boxes_norm) > 0:
                gt_boxes_norm = gt_boxes_norm.cpu().numpy()
                gt_boxes = gt_boxes_norm * np.array([W, H, W, H])  # è½¬æ¢ä¸ºåƒç´ åæ ‡
            elif isinstance(gt_boxes_norm, list) and len(gt_boxes_norm) > 0:
                gt_boxes = np.array(gt_boxes_norm) * np.array([W, H, W, H])
            else:
                gt_boxes = np.zeros((0, 4))
            
            if isinstance(gt_labels, torch.Tensor):
                gt_labels = gt_labels.cpu().numpy()
            elif isinstance(gt_labels, list):
                gt_labels = np.array(gt_labels)
        else:
            gt_boxes = np.zeros((0, 4))
            gt_labels = np.array([], dtype=np.int64)
        
        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        vis_img = create_visualization(
            rgb_img, thermal_img,
            pred_boxes, pred_scores, pred_labels,
            gt_boxes, gt_labels,
            class_names, H, W
        )
        
        vis_images.append(vis_img)
    
    return vis_images


def decode_predictions(
    cls_pred: torch.Tensor,
    bbox_pred: torch.Tensor,
    centerness_pred: torch.Tensor,  # â† æ–°å¢
    img_h: int,
    img_w: int,
    score_thresh: float = 0.05,  # ğŸ”¥ ä»0.3æ”¹ä¸º0.05 â­â­â­
    nms_thresh: float = 0.5,  # â† æ–°å¢
    max_detections: int = 100  # ğŸ†• æ¯å¼ å›¾æœ€å¤šä¿ç•™çš„æ£€æµ‹æ¡†æ•°é‡ â­â­â­
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    è§£ç é¢„æµ‹ç»“æœï¼ˆä¿®å¤ï¼šæ·»åŠ centernesså’ŒNMSï¼‰
    
    å‚æ•°ï¼š
        cls_pred: (num_classes, H', W') åˆ†ç±»é¢„æµ‹
        bbox_pred: (4, H', W') è¾¹ç•Œæ¡†é¢„æµ‹
        centerness_pred: (1, H', W') ä¸­å¿ƒåº¦é¢„æµ‹
        img_h, img_w: åŸå§‹å›¾åƒå°ºå¯¸
        score_thresh: åˆ†æ•°é˜ˆå€¼
        nms_thresh: NMS IoUé˜ˆå€¼
        
    è¿”å›ï¼š
        boxes: (N, 4) [x1, y1, x2, y2]
        scores: (N,)
        labels: (N,)
    """
    device = cls_pred.device
    num_channels, H, W = cls_pred.shape
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ’é™¤èƒŒæ™¯ç±»ï¼ˆæ¨¡å‹è¾“å‡º8ä¸ªé€šé“ï¼Œå‰7ä¸ªæ˜¯å‰æ™¯ç±»ï¼‰ â­â­â­
    num_classes = min(num_channels, 7)  # åªå–å‰7ä¸ªå‰æ™¯ç±»
    cls_pred_fg = cls_pred[:num_classes]  # (7, H, W)
    
    # âœ… ä¿®å¤ï¼šè®¡ç®—æœ€ç»ˆåˆ†æ•° = cls_score * centerness
    cls_scores = torch.sigmoid(cls_pred_fg)  # (7, H, W)
    
    if centerness_pred is not None:
        centerness_scores = torch.sigmoid(centerness_pred)  # (1, H, W)
        # æ¯ä¸ªç±»åˆ«çš„åˆ†æ•°éƒ½ä¹˜ä»¥ centerness
        final_scores = cls_scores * centerness_scores  # (num_classes, H, W)
    else:
        final_scores = cls_scores
    
    # æ‰¾åˆ°æ‰€æœ‰é«˜äºé˜ˆå€¼çš„ä½ç½®
    max_scores, max_labels = final_scores.max(dim=0)  # (H, W)
    mask = max_scores > score_thresh
    
    if mask.sum() == 0:
        # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡
        return np.zeros((0, 4)), np.zeros(0), np.zeros(0, dtype=np.int64)
    
    # è·å–æ£€æµ‹ä½ç½®
    indices = mask.nonzero(as_tuple=False)  # (N, 2) [h, w]
    selected_scores = max_scores[mask].cpu().numpy()
    selected_labels = max_labels[mask].cpu().numpy()
    
    # è§£ç è¾¹ç•Œæ¡†ï¼ˆFCOSé£æ ¼ï¼šl, t, r, bï¼‰
    stride = img_h / H
    boxes = []
    
    for idx in indices:
        h_idx, w_idx = idx[0].item(), idx[1].item()
        
        # è·å–è¾¹ç•Œæ¡†é¢„æµ‹
        l = bbox_pred[0, h_idx, w_idx].item()
        t = bbox_pred[1, h_idx, w_idx].item()
        r = bbox_pred[2, h_idx, w_idx].item()
        b = bbox_pred[3, h_idx, w_idx].item()
        
        # è½¬æ¢ä¸ºåƒç´ åæ ‡
        cx = (w_idx + 0.5) * stride
        cy = (h_idx + 0.5) * stride
        
        x1 = cx - l * stride
        y1 = cy - t * stride
        x2 = cx + r * stride
        y2 = cy + b * stride
        
        # è£å‰ªåˆ°å›¾åƒèŒƒå›´å†…
        x1 = np.clip(x1, 0, img_w)
        y1 = np.clip(y1, 0, img_h)
        x2 = np.clip(x2, 0, img_w)
        y2 = np.clip(y2, 0, img_h)
        
        boxes.append([x1, y1, x2, y2])
    
    boxes = np.array(boxes) if len(boxes) > 0 else np.zeros((0, 4))
    
    # âœ… æ·»åŠ  NMS
    if len(boxes) > 0:
        try:
            from torchvision.ops import nms
            boxes_tensor = torch.from_numpy(boxes).float().to(device)
            scores_tensor = torch.from_numpy(selected_scores).float().to(device)
            
            keep_indices = nms(boxes_tensor, scores_tensor, nms_thresh)
            keep_indices = keep_indices.cpu().numpy()
            
            boxes = boxes[keep_indices]
            selected_scores = selected_scores[keep_indices]
            selected_labels = selected_labels[keep_indices]
        except Exception as e:
            # å¦‚æœNMSå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹ç»“æœ
            print(f"Warning: NMS failed: {e}")
    
    # ğŸ†• é™åˆ¶æœ€å¤§æ£€æµ‹æ¡†æ•°é‡ â­â­â­
    if len(boxes) > max_detections:
        # æŒ‰åˆ†æ•°æ’åºï¼Œåªä¿ç•™å‰ max_detections ä¸ª
        top_k_indices = np.argsort(selected_scores)[::-1][:max_detections]
        boxes = boxes[top_k_indices]
        selected_scores = selected_scores[top_k_indices]
        selected_labels = selected_labels[top_k_indices]
    
    return boxes, selected_scores, selected_labels


def create_visualization(
    rgb_img: np.ndarray,
    thermal_img: np.ndarray,
    pred_boxes: np.ndarray,
    pred_scores: np.ndarray,
    pred_labels: np.ndarray,
    gt_boxes: List,
    gt_labels: List,
    class_names: List[str],
    img_h: int,
    img_w: int
) -> np.ndarray:
    """
    åˆ›å»ºå¯è§†åŒ–å›¾åƒï¼ˆRGB + Thermal å¹¶æ’æ˜¾ç¤ºï¼‰
    
    è¿”å›ï¼š
        vis_img: (H, W*2, 3) RGBå›¾åƒ
    """
    # åˆ›å»ºå›¾åƒ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    # RGB image + prediction boxes
    ax1.imshow(rgb_img)
    ax1.set_title('RGB + Predictions', fontsize=14, fontweight='bold')
    ax1.axis('off')
    
    # Draw prediction boxes (red)
    for box, score, label in zip(pred_boxes, pred_scores, pred_labels):
        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        
        rect = patches.Rectangle(
            (x1, y1), w, h,
            linewidth=2, edgecolor='red', facecolor='none'
        )
        ax1.add_patch(rect)
        
        # Label text
        label_text = f'{class_names[label]}: {score:.2f}'
        ax1.text(
            x1, y1 - 5, label_text,
            color='red', fontsize=10, weight='bold',
            bbox=dict(facecolor='white', alpha=0.7, pad=2, edgecolor='red')
        )
    
    # Draw GT boxes (green dashed)
    for box, label in zip(gt_boxes, gt_labels):
        if isinstance(box, torch.Tensor):
            box = box.cpu().numpy()
        if isinstance(box, list):
            box = np.array(box)
        
        # Convert normalized coordinates to pixel coordinates
        if box.max() <= 1.0:
            box = box * np.array([img_w, img_h, img_w, img_h])
        
        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        
        rect = patches.Rectangle(
            (x1, y1), w, h,
            linewidth=2, edgecolor='lime', facecolor='none', linestyle='--'
        )
        ax1.add_patch(rect)
        
        # GT label
        gt_text = f'GT: {class_names[label]}'
        ax1.text(
            x1, y2 + 15, gt_text,
            color='lime', fontsize=9, weight='bold',
            bbox=dict(facecolor='black', alpha=0.5, pad=2)
        )
    
    # Thermal image + prediction boxes
    ax2.imshow(thermal_img, cmap='hot')
    ax2.set_title('Thermal + Predictions', fontsize=14, fontweight='bold')
    ax2.axis('off')
    
    # Draw prediction boxes (cyan)
    for box, score, label in zip(pred_boxes, pred_scores, pred_labels):
        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        
        rect = patches.Rectangle(
            (x1, y1), w, h,
            linewidth=2, edgecolor='cyan', facecolor='none'
        )
        ax2.add_patch(rect)
    
    # Draw GT boxes (green dashed)
    for box in gt_boxes:
        if isinstance(box, torch.Tensor):
            box = box.cpu().numpy()
        if isinstance(box, list):
            box = np.array(box)
        
        if box.max() <= 1.0:
            box = box * np.array([img_w, img_h, img_w, img_h])
        
        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        
        rect = patches.Rectangle(
            (x1, y1), w, h,
            linewidth=2, edgecolor='lime', facecolor='none', linestyle='--'
        )
        ax2.add_patch(rect)
    
    # Add legend
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], color='red', lw=2, label='Predictions'),
        Line2D([0], [0], color='lime', lw=2, linestyle='--', label='Ground Truth')
    ]
    ax1.legend(handles=legend_elements, loc='upper right', fontsize=10)
    
    plt.tight_layout()
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå…¼å®¹ä¸åŒmatplotlibç‰ˆæœ¬ï¼‰
    fig.canvas.draw()
    
    # å°è¯•ä½¿ç”¨buffer_rgbaæˆ–tostring_rgb
    try:
        # æ–°ç‰ˆæœ¬matplotlib
        buf = fig.canvas.buffer_rgba()
        img = np.asarray(buf)
        img = img[:, :, :3]  # åªå–RGBé€šé“
    except AttributeError:
        try:
            # æ—§ç‰ˆæœ¬matplotlib
            img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
            img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        except AttributeError:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PIL
            buf = io.BytesIO()
            fig.savefig(buf, format='png', bbox_inches='tight', dpi=100)
            buf.seek(0)
            img = np.array(Image.open(buf))
            img = img[:, :, :3]  # åªå–RGBé€šé“
    
    plt.close(fig)
    
    return img


def images_to_tensorboard_grid(images: List[np.ndarray], nrow: int = 2) -> torch.Tensor:
    """
    å°†å›¾åƒåˆ—è¡¨è½¬æ¢ä¸ºTensorBoardç½‘æ ¼
    
    å‚æ•°ï¼š
        images: å›¾åƒåˆ—è¡¨ï¼Œæ¯ä¸ªä¸º (H, W, 3) numpyæ•°ç»„
        nrow: æ¯è¡Œå›¾åƒæ•°
        
    è¿”å›ï¼š
        grid: (3, H_total, W_total) tensor
    """
    if len(images) == 0:
        return torch.zeros(3, 100, 100)
    
    # è½¬æ¢ä¸ºtensor
    tensors = []
    for img in images:
        # (H, W, 3) -> (3, H, W)
        tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0
        tensors.append(tensor)
    
    # åˆ›å»ºç½‘æ ¼
    from torchvision.utils import make_grid
    grid = make_grid(tensors, nrow=nrow, padding=10, normalize=False)
    
    return grid


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("æµ‹è¯•å¯è§†åŒ–å·¥å…·...")
    
    # æ¨¡æ‹Ÿæ•°æ®
    B, T, H, W = 2, 5, 640, 640
    rgb_frames = torch.randn(B, T, 3, H, W)
    thermal_frames = torch.randn(B, T, 1, H, W)
    
    # æ¨¡æ‹Ÿé¢„æµ‹
    predictions = []
    for t in range(T):
        pred = {
            'cls': torch.randn(B, 7, 40, 40),
            'bbox': torch.randn(B, 4, 40, 40),
        }
        predictions.append(pred)
    
    # æ¨¡æ‹Ÿç›®æ ‡
    targets = [
        {'boxes': [[0.1, 0.1, 0.3, 0.3]], 'labels': [0]},
        {'boxes': [[0.5, 0.5, 0.7, 0.7]], 'labels': [1]}
    ]
    
    class_names = ['ship', 'car', 'cyclist', 'pedestrian', 'bus', 'drone', 'plane']
    
    # å¯è§†åŒ–
    vis_images = visualize_detection_results(
        rgb_frames, thermal_frames, predictions, targets, class_names
    )
    
    print(f"ç”Ÿæˆäº† {len(vis_images)} å¼ å¯è§†åŒ–å›¾åƒ")
    print(f"å›¾åƒå½¢çŠ¶: {vis_images[0].shape}")
    
    # è½¬æ¢ä¸ºç½‘æ ¼
    grid = images_to_tensorboard_grid(vis_images)
    print(f"ç½‘æ ¼å½¢çŠ¶: {grid.shape}")
    
    print("\nâœ“ å¯è§†åŒ–å·¥å…·æµ‹è¯•é€šè¿‡ï¼")

