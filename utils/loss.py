"""
æŸå¤±å‡½æ•°æ¨¡å—
åŒ…å« Focal Loss, CIoU Loss, Dice Loss ç­‰
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, List


class FocalLoss(nn.Module):
    """
    Focal Loss for Dense Object Detection
    
    ç”¨äºè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œé™ä½æ˜“åˆ†æ ·æœ¬çš„æƒé‡
    
    å‚æ•°ï¼š
        alpha (float): å¹³è¡¡å› å­
        gamma (float): èšç„¦å‚æ•°
        reduction (str): 'none', 'mean', 'sum'
    """
    
    def __init__(
        self,
        alpha: float = 0.25,
        gamma: float = 2.0,
        reduction: str = 'mean',
        ignore_index: int = -100
    ):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        self.ignore_index = ignore_index
    
    def forward(
        self,
        inputs: torch.Tensor,
        targets: torch.Tensor
    ) -> torch.Tensor:
        """
        å‚æ•°ï¼š
            inputs: (B, C, H, W) æˆ– (B*H*W, C) é¢„æµ‹ logits
            targets: (B, H, W) æˆ– (B*H*W,) çœŸå®æ ‡ç­¾ï¼ˆ0/1ï¼‰
            
        è¿”å›ï¼š
            loss: æ ‡é‡æŸå¤±
        """
        # å±•å¹³
        if inputs.dim() == 4:
            B, C, H, W = inputs.shape
            inputs = inputs.permute(0, 2, 3, 1).reshape(-1, C)
            targets = targets.view(-1)
        
        # è¿‡æ»¤æ‰ ignore_index çš„ä½ç½®
        valid_mask = targets != self.ignore_index
        if valid_mask.sum() == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç›®æ ‡ï¼Œè¿”å› 0
            return torch.tensor(0.0, device=inputs.device, requires_grad=True)
        
        inputs = inputs[valid_mask]
        targets = targets[valid_mask]
        
        # åº”ç”¨ sigmoid
        p = torch.sigmoid(inputs)
        
        # äºŒåˆ†ç±» Focal Loss
        if inputs.shape[1] == 1:
            p = p.squeeze(1)
            ce_loss = F.binary_cross_entropy_with_logits(
                inputs.squeeze(1), targets.float(), reduction='none'
            )
            p_t = p * targets + (1 - p) * (1 - targets)
            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
        else:
            # å¤šåˆ†ç±»
            ce_loss = F.cross_entropy(inputs, targets.long(), reduction='none')
            p_t = p.gather(1, targets.long().unsqueeze(1)).squeeze(1)
            alpha_t = self.alpha
        
        # Focal weight
        focal_weight = (1 - p_t) ** self.gamma
        loss = alpha_t * focal_weight * ce_loss
        
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss


class WeightedFocalLoss(nn.Module):
    """
    ç±»åˆ«åŠ æƒçš„Focal Loss
    
    ç”¨äºè§£å†³ä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œä¸ºæ¯ä¸ªç±»åˆ«è®¾ç½®ä¸åŒçš„æƒé‡
    
    å‚æ•°ï¼š
        class_weights (dict or list): æ¯ä¸ªç±»åˆ«çš„æƒé‡
        gamma (float): èšç„¦å‚æ•°
        reduction (str): 'none', 'mean', 'sum'
        ignore_index (int): å¿½ç•¥çš„æ ‡ç­¾ID
    """
    
    def __init__(
        self,
        class_weights: dict = None,
        gamma: float = 2.0,
        reduction: str = 'mean',
        ignore_index: int = -100
    ):
        super().__init__()
        
        # é»˜è®¤ç±»åˆ«æƒé‡ï¼ˆæ ¹æ®RGBT-Tinyæ•°æ®é›†ç»Ÿè®¡ï¼‰
        if class_weights is None:
            class_weights = {
                0: 0.9,   # ship     (9.86%)
                1: 0.4,   # car      (45.07%) - æœ€å¤šï¼Œé™ä½æƒé‡
                2: 0.8,   # cyclist  (11.67%)
                3: 0.6,   # pedestrian (25.27%)
                4: 1.0,   # bus      (2.63%)
                5: 1.2,   # drone    (1.92%) - æœ€å°‘ï¼Œæé«˜æƒé‡
                6: 1.0,   # plane    (3.59%)
                7: 0.1    # background (å¾ˆå¤š) - æä½æƒé‡
            }
        
        # è½¬æ¢ä¸ºtensor
        if isinstance(class_weights, dict):
            # æ‰¾åˆ°æœ€å¤§çš„ç±»åˆ«ID
            max_class_id = max(class_weights.keys())
            # åˆ›å»ºæƒé‡tensor
            weight_tensor = torch.ones(max_class_id + 1)
            for cls_id, weight in class_weights.items():
                weight_tensor[cls_id] = weight
            self.class_weights = weight_tensor
        else:
            self.class_weights = torch.tensor(class_weights, dtype=torch.float32)
        
        self.gamma = gamma
        self.reduction = reduction
        self.ignore_index = ignore_index
    
    def forward(
        self,
        inputs: torch.Tensor,
        targets: torch.Tensor
    ) -> torch.Tensor:
        """
        å‚æ•°ï¼š
            inputs: (B, C, H, W) æˆ– (B*H*W, C) é¢„æµ‹ logits
            targets: (B, H, W) æˆ– (B*H*W,) çœŸå®æ ‡ç­¾
            
        è¿”å›ï¼š
            loss: æ ‡é‡æŸå¤±
        """
        # å±•å¹³
        if inputs.dim() == 4:
            B, C, H, W = inputs.shape
            inputs = inputs.permute(0, 2, 3, 1).reshape(-1, C)
            targets = targets.view(-1)
        
        # è¿‡æ»¤æ‰ ignore_index çš„ä½ç½®
        valid_mask = targets != self.ignore_index
        if valid_mask.sum() == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç›®æ ‡ï¼Œè¿”å› 0
            return torch.tensor(0.0, device=inputs.device, requires_grad=True)
        
        inputs = inputs[valid_mask]
        targets = targets[valid_mask]
        
        # å°†ç±»åˆ«æƒé‡ç§»åˆ°æ­£ç¡®çš„è®¾å¤‡
        if self.class_weights.device != inputs.device:
            self.class_weights = self.class_weights.to(inputs.device)
        
        # è®¡ç®—äº¤å‰ç†µï¼ˆä¸reductionï¼Œä¿ç•™æ¯ä¸ªæ ·æœ¬çš„lossï¼‰
        ce_loss = F.cross_entropy(inputs, targets.long(), reduction='none')
        
        # è®¡ç®—pt (é¢„æµ‹æ­£ç¡®ç±»åˆ«çš„æ¦‚ç‡)
        pt = torch.exp(-ce_loss)
        
        # è·å–æ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«æƒé‡
        alpha = self.class_weights[targets.long()]
        
        # Focal Loss
        focal_loss = alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


class CIoULoss(nn.Module):
    """
    Complete IoU Loss
    
    è€ƒè™‘äº†è¾¹ç•Œæ¡†çš„é‡å é¢ç§¯ã€ä¸­å¿ƒç‚¹è·ç¦»ã€å®½é«˜æ¯”
    
    å‚æ•°ï¼š
        eps (float): é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°
    """
    
    def __init__(self, eps: float = 1e-7):
        super().__init__()
        self.eps = eps
    
    def forward(
        self,
        pred_boxes: torch.Tensor,
        target_boxes: torch.Tensor
    ) -> torch.Tensor:
        """
        å‚æ•°ï¼š
            pred_boxes: (N, 4) é¢„æµ‹æ¡† [x1, y1, x2, y2] æˆ– [l, t, r, b]
            target_boxes: (N, 4) çœŸå®æ¡†
            
        è¿”å›ï¼š
            loss: CIoU æŸå¤±
        """
        # è®¡ç®— IoU
        inter_x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])
        inter_y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])
        inter_x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])
        inter_y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])
        
        inter_area = (inter_x2 - inter_x1).clamp(min=0) * (inter_y2 - inter_y1).clamp(min=0)
        
        pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])
        target_area = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])
        
        union_area = pred_area + target_area - inter_area + self.eps
        iou = inter_area / union_area
        
        # è®¡ç®—ä¸­å¿ƒç‚¹è·ç¦»
        pred_center_x = (pred_boxes[:, 0] + pred_boxes[:, 2]) / 2
        pred_center_y = (pred_boxes[:, 1] + pred_boxes[:, 3]) / 2
        target_center_x = (target_boxes[:, 0] + target_boxes[:, 2]) / 2
        target_center_y = (target_boxes[:, 1] + target_boxes[:, 3]) / 2
        
        center_distance = (pred_center_x - target_center_x) ** 2 + (pred_center_y - target_center_y) ** 2
        
        # è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢çš„å¯¹è§’çº¿è·ç¦»
        enclose_x1 = torch.min(pred_boxes[:, 0], target_boxes[:, 0])
        enclose_y1 = torch.min(pred_boxes[:, 1], target_boxes[:, 1])
        enclose_x2 = torch.max(pred_boxes[:, 2], target_boxes[:, 2])
        enclose_y2 = torch.max(pred_boxes[:, 3], target_boxes[:, 3])
        
        enclose_diagonal = (enclose_x2 - enclose_x1) ** 2 + (enclose_y2 - enclose_y1) ** 2 + self.eps
        
        # è®¡ç®—å®½é«˜æ¯”ä¸€è‡´æ€§
        pred_w = (pred_boxes[:, 2] - pred_boxes[:, 0]).clamp(min=self.eps)
        pred_h = (pred_boxes[:, 3] - pred_boxes[:, 1]).clamp(min=self.eps)
        target_w = (target_boxes[:, 2] - target_boxes[:, 0]).clamp(min=self.eps)
        target_h = (target_boxes[:, 3] - target_boxes[:, 1]).clamp(min=self.eps)
        
        # ä½¿ç”¨å®‰å…¨çš„ atan è®¡ç®—ï¼Œé¿å…æç«¯å€¼
        v = (4 / (torch.pi ** 2)) * torch.pow(
            torch.atan(target_w / target_h) - torch.atan(pred_w / pred_h), 2
        )
        
        with torch.no_grad():
            alpha = v / ((1 - iou + v).clamp(min=self.eps))
        
        # CIoUï¼Œé™åˆ¶èŒƒå›´é¿å…æ•°å€¼çˆ†ç‚¸
        ciou = (iou - (center_distance / enclose_diagonal + alpha * v)).clamp(min=-1.0, max=1.0)
        
        # æŸå¤±ï¼Œå¹¶é™åˆ¶èŒƒå›´
        loss = (1 - ciou).clamp(min=0.0, max=2.0)
        
        return loss.mean()


class DiceLoss(nn.Module):
    """
    Dice Loss
    
    å¸¸ç”¨äºåˆ†å‰²ä»»åŠ¡ï¼Œä¹Ÿå¯ç”¨äºè¾¹ç¼˜æ£€æµ‹
    
    å‚æ•°ï¼š
        smooth (float): å¹³æ»‘é¡¹
    """
    
    def __init__(self, smooth: float = 1.0):
        super().__init__()
        self.smooth = smooth
    
    def forward(
        self,
        inputs: torch.Tensor,
        targets: torch.Tensor
    ) -> torch.Tensor:
        """
        å‚æ•°ï¼š
            inputs: (B, C, H, W) é¢„æµ‹
            targets: (B, C, H, W) çœŸå®æ ‡ç­¾
            
        è¿”å›ï¼š
            loss: Dice æŸå¤±
        """
        # åº”ç”¨ sigmoid
        inputs = torch.sigmoid(inputs)
        
        # å±•å¹³
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        
        # è®¡ç®— Dice ç³»æ•°
        intersection = (inputs * targets).sum()
        dice = (2.0 * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)
        
        # æŸå¤±
        loss = 1 - dice
        
        return loss


def compute_loss(
    outputs: List[Dict[str, torch.Tensor]],
    targets: List[Dict[str, torch.Tensor]],
    loss_weights: Dict[str, float] = None
) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
    """
    è®¡ç®—æ€»æŸå¤±
    
    å‚æ•°ï¼š
        outputs: æ¨¡å‹è¾“å‡ºï¼ŒList of dict
            - 'cls': (B, num_classes, H, W)
            - 'bbox': (B, 4, H, W)
            - 'centerness': (B, 1, H, W)
            - 'offset': (B, 2, H, W)
        targets: çœŸå®æ ‡ç­¾ï¼ŒList of dict
            - 'cls': (B, H, W)
            - 'bbox': (B, N, 4)
            - 'valid': (B, H, W) æœ‰æ•ˆä½ç½® mask
        loss_weights: æŸå¤±æƒé‡
        
    è¿”å›ï¼š
        total_loss: æ€»æŸå¤±
        loss_dict: å„æŸå¤±é¡¹å­—å…¸
    """
    if loss_weights is None:
        loss_weights = {
            'cls': 1.0,
            'bbox': 5.0,
            'centerness': 1.0,
            'offset': 2.0
        }
    
    # åˆå§‹åŒ–æŸå¤±å‡½æ•°
    # ğŸ”¥ ä¿®å¤Shipé¢„æµ‹åå‘ï¼šä½¿ç”¨ç±»åˆ«åŠ æƒçš„Focal Loss
    # ä¸ºæ¯ä¸ªç±»åˆ«è®¾ç½®ä¸åŒçš„æƒé‡ï¼Œè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
    class_weights = loss_weights.get('class_weights', None)  # ğŸ†• ä»é…ç½®è¯»å– â­â­â­
    focal_loss_fn = WeightedFocalLoss(
        gamma=loss_weights.get('cls_gamma', 2.0),
        class_weights=class_weights  # â­â­â­ ä¼ å…¥ç±»åˆ«æƒé‡
    )
    ciou_loss_fn = CIoULoss()
    dice_loss_fn = DiceLoss()
    
    # ç´¯ç§¯å„æŸå¤±é¡¹
    total_cls_loss = 0.0
    total_bbox_loss = 0.0
    total_centerness_loss = 0.0
    total_offset_loss = 0.0
    
    num_frames = len(outputs)
    
    for t in range(num_frames):
        output = outputs[t]
        target = targets[t] if t < len(targets) else targets[-1]
        
        # 1. åˆ†ç±»æŸå¤±ï¼ˆFocal Lossï¼‰
        cls_pred = output['cls']  # (B, num_classes, H, W)
        cls_target = target.get('cls', None)
        
        if cls_target is not None:
            # âœ… ä¿®å¤ï¼šReshape to (B*H*W, num_classes) for Focal Loss
            B, C, H, W = cls_pred.shape
            cls_pred_flat = cls_pred.permute(0, 2, 3, 1).reshape(-1, C)  # (B*H*W, C)
            cls_target_flat = cls_target.reshape(-1)  # (B*H*W,)
            
            cls_loss = focal_loss_fn(cls_pred_flat, cls_target_flat)
            
            # æ£€æµ‹ NaN
            if torch.isnan(cls_loss) or torch.isinf(cls_loss):
                print(f"Warning: NaN/Inf detected in cls_loss at frame {t}, skipping...")
                cls_loss = torch.tensor(0.0, device=cls_loss.device, requires_grad=True)
            
            total_cls_loss += cls_loss
        
        # 2. è¾¹ç•Œæ¡†æŸå¤±ï¼ˆCIoU Lossï¼‰
        bbox_pred = output['bbox']  # (B, 4, H, W)
        bbox_target = target.get('bbox', None)
        valid_mask = target.get('valid', None)
        
        if bbox_target is not None and valid_mask is not None:
            # åªåœ¨æœ‰ç›®æ ‡çš„ä½ç½®è®¡ç®— bbox æŸå¤±
            B, _, H, W = bbox_pred.shape
            
            # å°†é¢„æµ‹å’Œç›®æ ‡éƒ½è½¬æ¢ä¸º (N, 4) æ ¼å¼
            valid_indices = valid_mask.nonzero(as_tuple=False)  # (N, 3) [b, h, w]
            
            if len(valid_indices) > 0:
                # è·å–é¢„æµ‹çš„ bbox (FCOS style: l, t, r, b)
                bbox_pred_ltrb = bbox_pred[
                    valid_indices[:, 0],
                    :,
                    valid_indices[:, 1],
                    valid_indices[:, 2]
                ]  # (N, 4) [l, t, r, b]
                
                # è·å–ç›®æ ‡çš„ bbox (FCOS style: l, t, r, b)
                bbox_target_ltrb = bbox_target[
                    valid_indices[:, 0],
                    :,
                    valid_indices[:, 1],
                    valid_indices[:, 2]
                ]  # (N, 4) [l, t, r, b]
                
                # è½¬æ¢ä¸º (x1, y1, x2, y2) æ ¼å¼ç”¨äº CIoU Loss
                # åŠ¨æ€è®¡ç®—strideï¼ˆå‡è®¾è¾“å…¥å›¾åƒä¸º640x640ï¼‰
                img_size = 640  # å¯ä»¥ä»configè·å–
                stride = img_size / H  # è®¡ç®—ä¸‹é‡‡æ ·å€æ•°
                grid_h = valid_indices[:, 1].float()
                grid_w = valid_indices[:, 2].float()
                center_x = (grid_w + 0.5) * stride
                center_y = (grid_h + 0.5) * stride
                
                # é¢„æµ‹æ¡†è½¬æ¢: (l, t, r, b) -> (x1, y1, x2, y2)
                pred_x1 = center_x - bbox_pred_ltrb[:, 0] * stride
                pred_y1 = center_y - bbox_pred_ltrb[:, 1] * stride
                pred_x2 = center_x + bbox_pred_ltrb[:, 2] * stride
                pred_y2 = center_y + bbox_pred_ltrb[:, 3] * stride
                bbox_pred_xyxy = torch.stack([pred_x1, pred_y1, pred_x2, pred_y2], dim=1)
                
                # ç›®æ ‡æ¡†è½¬æ¢: (l, t, r, b) -> (x1, y1, x2, y2)
                target_x1 = center_x - bbox_target_ltrb[:, 0] * stride
                target_y1 = center_y - bbox_target_ltrb[:, 1] * stride
                target_x2 = center_x + bbox_target_ltrb[:, 2] * stride
                target_y2 = center_y + bbox_target_ltrb[:, 3] * stride
                bbox_target_xyxy = torch.stack([target_x1, target_y1, target_x2, target_y2], dim=1)
                
                # è®¡ç®— CIoU Loss
                bbox_loss = ciou_loss_fn(bbox_pred_xyxy, bbox_target_xyxy)
                
                # æ£€æµ‹ NaN å¹¶æ›¿æ¢ä¸º 0
                if torch.isnan(bbox_loss) or torch.isinf(bbox_loss):
                    print(f"Warning: NaN/Inf detected in bbox_loss at frame {t}, skipping...")
                    bbox_loss = torch.tensor(0.0, device=bbox_loss.device, requires_grad=True)
                
                total_bbox_loss += bbox_loss
        
        # 3. ä¸­å¿ƒåº¦æŸå¤±ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'centerness' in output:
            centerness_pred = output['centerness']
            centerness_target = target.get('centerness', None)
            
            if centerness_target is not None:
                # ä½¿ç”¨ binary_cross_entropy_with_logits ä»¥æ”¯æŒ AMP
                # æ¨¡å‹è¾“å‡ºåº”è¯¥æ˜¯ logitsï¼ˆæœªç» sigmoidï¼‰ï¼Œè¿™é‡Œä¼šè‡ªåŠ¨åº”ç”¨ sigmoid
                centerness_loss = F.binary_cross_entropy_with_logits(
                    centerness_pred,
                    centerness_target,
                    reduction='mean'
                )
                total_centerness_loss += centerness_loss
        
        # 4. åç§»æŸå¤±ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'offset' in output:
            offset_pred = output['offset']
            offset_target = target.get('offset', None)
            
            if offset_target is not None:
                offset_loss = F.smooth_l1_loss(offset_pred, offset_target)
                total_offset_loss += offset_loss
    
    # å¹³å‡å„å¸§æŸå¤±
    total_cls_loss /= num_frames
    total_bbox_loss /= num_frames
    total_centerness_loss /= num_frames
    total_offset_loss /= max(num_frames - 1, 1)  # åç§»åªæœ‰ T-1 ä¸ª
    
    # åŠ æƒæ±‚å’Œ
    weighted_cls_loss = loss_weights['cls'] * total_cls_loss
    weighted_bbox_loss = loss_weights['bbox'] * total_bbox_loss
    weighted_centerness_loss = loss_weights['centerness'] * total_centerness_loss
    weighted_offset_loss = loss_weights['offset'] * total_offset_loss
    
    total_loss = (
        weighted_cls_loss +
        weighted_bbox_loss +
        weighted_centerness_loss +
        weighted_offset_loss
    )
    
    # ç¡®ä¿è¿”å›çš„ total_loss æ˜¯ Tensorï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
    if not isinstance(total_loss, torch.Tensor):
        # å¦‚æœæ‰€æœ‰æŸå¤±éƒ½æ˜¯ 0ï¼Œåˆ›å»ºä¸€ä¸ªéœ€è¦æ¢¯åº¦çš„é›¶å¼ é‡
        total_loss = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)
    
    # æ„å»ºæŸå¤±å­—å…¸ï¼ˆå­˜å‚¨åŠ æƒåçš„æŸå¤±ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤ºï¼‰
    loss_dict = {
        'loss': total_loss.item() if isinstance(total_loss, torch.Tensor) else float(total_loss),
        'cls_loss': weighted_cls_loss.item() if isinstance(weighted_cls_loss, torch.Tensor) else float(weighted_cls_loss),
        'bbox_loss': weighted_bbox_loss.item() if isinstance(weighted_bbox_loss, torch.Tensor) else float(weighted_bbox_loss),
        'centerness_loss': weighted_centerness_loss.item() if isinstance(weighted_centerness_loss, torch.Tensor) else float(weighted_centerness_loss),
        'offset_loss': weighted_offset_loss.item() if isinstance(weighted_offset_loss, torch.Tensor) else float(weighted_offset_loss)
    }
    
    return total_loss, loss_dict


if __name__ == "__main__":
    # æµ‹è¯•æŸå¤±å‡½æ•°
    print("Testing Loss Functions...")
    
    # æµ‹è¯• Focal Loss
    print("\n1. Focal Loss:")
    focal_loss = FocalLoss()
    pred = torch.randn(2, 1, 64, 64)
    target = torch.randint(0, 2, (2, 64, 64)).float()
    loss = focal_loss(pred, target)
    print(f"   Loss: {loss.item():.4f}")
    
    # æµ‹è¯• CIoU Loss
    print("\n2. CIoU Loss:")
    ciou_loss = CIoULoss()
    pred_boxes = torch.tensor([[10, 10, 50, 50], [20, 20, 60, 60]]).float()
    target_boxes = torch.tensor([[15, 15, 55, 55], [25, 25, 65, 65]]).float()
    loss = ciou_loss(pred_boxes, target_boxes)
    print(f"   Loss: {loss.item():.4f}")
    
    # æµ‹è¯• Dice Loss
    print("\n3. Dice Loss:")
    dice_loss = DiceLoss()
    pred = torch.randn(2, 1, 64, 64)
    target = torch.randint(0, 2, (2, 1, 64, 64)).float()
    loss = dice_loss(pred, target)
    print(f"   Loss: {loss.item():.4f}")
    
    print("\nâœ“ æ‰€æœ‰æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")

