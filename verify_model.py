"""
TLCFormer æ¨¡å‹éªŒè¯è„šæœ¬

ä½¿ç”¨ Mock æ•°æ®é›†éªŒè¯ï¼š
1. æ¨¡å‹ç½‘ç»œç»“æ„æ˜¯å¦æ­£ç¡®
2. å‰å‘ä¼ æ’­æ˜¯å¦æ­£å¸¸
3. åå‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—æ˜¯å¦æ­£å¸¸
4. æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸è®­ç»ƒ

è¿è¡Œæ–¹å¼ï¼š
    python verify_model.py
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import time
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')

from models import (
    OSFormer, OSFormerConfig, build_osformer,
    TLCFormer, TLCFormerConfig, build_tlcformer,
    MotionAwareDifferenceAttention,
    DeepLocalContrastModule,
    HybridTokenMixer
)


class MockRGBTDataset(Dataset):
    """
    Mock RGBT æ•°æ®é›†
    
    ç”Ÿæˆéšæœºçš„ RGB å’Œçƒ­çº¢å¤–å¸§åºåˆ—ç”¨äºéªŒè¯æ¨¡å‹
    """
    
    def __init__(
        self,
        num_samples: int = 100,
        num_frames: int = 5,
        img_size: int = 256,  # ä½¿ç”¨è¾ƒå°å°ºå¯¸åŠ å¿«éªŒè¯
        num_classes: int = 7
    ):
        self.num_samples = num_samples
        self.num_frames = num_frames
        self.img_size = img_size
        self.num_classes = num_classes
        
    def __len__(self):
        return self.num_samples
    
    def __getitem__(self, idx):
        # ç”Ÿæˆéšæœº RGB å¸§åºåˆ—
        rgb_frames = torch.randn(self.num_frames, 3, self.img_size, self.img_size)
        
        # ç”Ÿæˆéšæœºçƒ­çº¢å¤–å¸§åºåˆ—
        thermal_frames = torch.randn(self.num_frames, 1, self.img_size, self.img_size)
        
        # ç”Ÿæˆéšæœºç›®æ ‡æ ‡ç­¾
        # å‡è®¾ç‰¹å¾å›¾å°ºå¯¸ä¸º img_size / 8 (å› ä¸º neck æœ‰ä¸Šé‡‡æ ·)
        feat_size = self.img_size // 8
        
        targets = []
        for t in range(self.num_frames):
            target = {
                'cls': torch.randint(0, self.num_classes + 1, (feat_size, feat_size)),  # 0 æ˜¯èƒŒæ™¯
                'bbox': torch.rand(4, feat_size, feat_size) * 10,  # FCOS style: l, t, r, b
                'valid': torch.zeros(feat_size, feat_size),
                'centerness': torch.zeros(1, feat_size, feat_size)
            }
            
            # éšæœºè®¾ç½®ä¸€äº›ä½ç½®ä¸ºæœ‰æ•ˆç›®æ ‡
            num_targets = torch.randint(1, 5, (1,)).item()
            for _ in range(num_targets):
                h = torch.randint(0, feat_size, (1,)).item()
                w = torch.randint(0, feat_size, (1,)).item()
                target['valid'][h, w] = 1
                target['centerness'][0, h, w] = torch.rand(1).item()
            
            targets.append(target)
        
        return {
            'rgb_frames': rgb_frames,
            'thermal_frames': thermal_frames,
            'targets': targets
        }


def collate_fn(batch):
    """è‡ªå®šä¹‰ collate å‡½æ•°"""
    rgb_frames = torch.stack([item['rgb_frames'] for item in batch])
    thermal_frames = torch.stack([item['thermal_frames'] for item in batch])
    
    # å¤„ç† targets
    batch_size = len(batch)
    num_frames = len(batch[0]['targets'])
    
    targets = []
    for t in range(num_frames):
        frame_target = {
            'cls': torch.stack([batch[b]['targets'][t]['cls'] for b in range(batch_size)]),
            'bbox': torch.stack([batch[b]['targets'][t]['bbox'] for b in range(batch_size)]),
            'valid': torch.stack([batch[b]['targets'][t]['valid'] for b in range(batch_size)]),
            'centerness': torch.stack([batch[b]['targets'][t]['centerness'] for b in range(batch_size)])
        }
        targets.append(frame_target)
    
    return rgb_frames, thermal_frames, targets


def test_individual_modules():
    """æµ‹è¯•å„ä¸ªç‹¬ç«‹æ¨¡å—"""
    print("\n" + "=" * 60)
    print("1. æµ‹è¯•ç‹¬ç«‹æ¨¡å—")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯• MADA
    print("\n[1.1] æµ‹è¯• MADA (Motion-Aware Difference Attention)...")
    mada = MotionAwareDifferenceAttention(num_frames=3, in_channels=2, alpha=0.5).to(device)
    cube_input = torch.randn(2, 2, 128, 128, 3).to(device)
    
    try:
        cube_output = mada(cube_input)
        assert cube_output.shape == cube_input.shape, f"MADA è¾“å‡ºå½¢çŠ¶é”™è¯¯: {cube_output.shape}"
        print(f"  âœ“ è¾“å…¥: {cube_input.shape} -> è¾“å‡º: {cube_output.shape}")
        print(f"  âœ“ Î± å‚æ•°: {mada.alpha.item():.4f}")
    except Exception as e:
        print(f"  âœ— MADA æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯• DLCM
    print("\n[1.2] æµ‹è¯• DLCM (Deep Local Contrast Module)...")
    dlcm = DeepLocalContrastModule(in_channels=64, kernel_inner=3, kernel_outer=9).to(device)
    x_input = torch.randn(2, 64, 32, 32).to(device)
    
    try:
        x_output = dlcm(x_input)
        assert x_output.shape == x_input.shape, f"DLCM è¾“å‡ºå½¢çŠ¶é”™è¯¯: {x_output.shape}"
        print(f"  âœ“ è¾“å…¥: {x_input.shape} -> è¾“å‡º: {x_output.shape}")
        print(f"  âœ“ Î² å‚æ•°: {dlcm.beta.item():.4f}")
    except Exception as e:
        print(f"  âœ— DLCM æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯• HybridTokenMixer
    print("\n[1.3] æµ‹è¯• HybridTokenMixer (Max-Mean Hybrid Pooling)...")
    mixer = HybridTokenMixer(dim=96, pool_size=3).to(device)
    mixer.set_spatial(16, 16)
    tokens_input = torch.randn(2, 256, 96).to(device)
    
    try:
        tokens_output = mixer(tokens_input)
        assert tokens_output.shape == tokens_input.shape, f"Mixer è¾“å‡ºå½¢çŠ¶é”™è¯¯"
        print(f"  âœ“ è¾“å…¥: {tokens_input.shape} -> è¾“å‡º: {tokens_output.shape}")
    except Exception as e:
        print(f"  âœ— HybridTokenMixer æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\nâœ“ æ‰€æœ‰ç‹¬ç«‹æ¨¡å—æµ‹è¯•é€šè¿‡!")
    return True


def test_full_model_forward():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹çš„å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("2. æµ‹è¯•å®Œæ•´æ¨¡å‹å‰å‘ä¼ æ’­")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ä½¿ç”¨è¾ƒå°å°ºå¯¸åŠ å¿«æµ‹è¯•
    config = OSFormerConfig(
        num_frames=5,
        sample_frames=3,
        img_size=256,
        num_classes=7,
        embed_dim=48,  # å‡å°åµŒå…¥ç»´åº¦åŠ å¿«æµ‹è¯•
        depths=[1, 1, 2, 1],  # å‡å°æ·±åº¦
        use_mada=True,
        use_dlcm=True,
        use_doppler=False
    )
    
    print(f"\næ¨¡å‹é…ç½®:")
    print(f"  img_size: {config.img_size}")
    print(f"  embed_dim: {config.embed_dim}")
    print(f"  depths: {config.depths}")
    print(f"  use_mada: {config.use_mada}")
    print(f"  use_dlcm: {config.use_dlcm}")
    
    model = build_osformer(config).to(device)
    
    # æ‰“å°æ¨¡å‹ç»“æ„æ‘˜è¦
    num_params = sum(p.numel() for p in model.parameters())
    print(f"\næ¨¡å‹å‚æ•°é‡: {num_params / 1e6:.2f}M")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    B, T, H, W = 2, 5, 256, 256
    rgb_frames = torch.randn(B, T, 3, H, W).to(device)
    thermal_frames = torch.randn(B, T, 1, H, W).to(device)
    
    print(f"\nè¾“å…¥:")
    print(f"  RGB: {rgb_frames.shape}")
    print(f"  Thermal: {thermal_frames.shape}")
    
    try:
        start_time = time.time()
        with torch.no_grad():
            outputs = model(rgb_frames, thermal_frames)
        forward_time = time.time() - start_time
        
        print(f"\nè¾“å‡º (æ¨ç†æ—¶é—´: {forward_time:.3f}s):")
        for t, output in enumerate(outputs):
            if t == 0:  # åªæ‰“å°ç¬¬ä¸€å¸§
                print(f"  Frame {t}:")
                for key, val in output.items():
                    print(f"    {key}: {val.shape}")
        print(f"  ... (å…± {len(outputs)} å¸§)")
        
        print("\nâœ“ å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡!")
        return True, model
        
    except Exception as e:
        print(f"\nâœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_backward_and_gradient():
    """æµ‹è¯•åå‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("3. æµ‹è¯•åå‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    config = OSFormerConfig(
        num_frames=5,
        sample_frames=3,
        img_size=256,
        num_classes=7,
        embed_dim=48,
        depths=[1, 1, 2, 1],
        use_mada=True,
        use_dlcm=True
    )
    
    model = build_osformer(config).to(device)
    
    # å‡†å¤‡è¾“å…¥
    B, T, H, W = 2, 5, 256, 256
    rgb_frames = torch.randn(B, T, 3, H, W).to(device)
    thermal_frames = torch.randn(B, T, 1, H, W).to(device)
    
    try:
        # å‰å‘ä¼ æ’­
        outputs = model(rgb_frames, thermal_frames)
        
        # åˆ›å»ºå‡æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰
        loss = 0
        for output in outputs:
            loss += output['cls'].mean()
            loss += output['bbox'].mean()
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        has_grad = False
        grad_info = []
        for name, param in model.named_parameters():
            if param.grad is not None:
                has_grad = True
                grad_norm = param.grad.norm().item()
                if 'mada' in name or 'dlcm' in name:
                    grad_info.append((name, grad_norm))
        
        if has_grad:
            print("\nå…³é”®æ¨¡å—æ¢¯åº¦:")
            for name, grad_norm in grad_info[:5]:
                print(f"  {name}: {grad_norm:.6f}")
            print("\nâœ“ åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡!")
            return True
        else:
            print("\nâœ— æ²¡æœ‰è®¡ç®—æ¢¯åº¦!")
            return False
            
    except Exception as e:
        print(f"\nâœ— åå‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_loop():
    """æµ‹è¯•å®Œæ•´è®­ç»ƒå¾ªç¯"""
    print("\n" + "=" * 60)
    print("4. æµ‹è¯•è®­ç»ƒå¾ªç¯ (3 ä¸ª epoch)")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºå°å‹æ¨¡å‹å’Œæ•°æ®é›†
    config = OSFormerConfig(
        num_frames=5,
        sample_frames=3,
        img_size=128,  # æ›´å°çš„å°ºå¯¸
        num_classes=7,
        embed_dim=32,  # æ›´å°çš„åµŒå…¥ç»´åº¦
        depths=[1, 1, 1, 1],
        use_mada=True,
        use_dlcm=True
    )
    
    model = build_osformer(config).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)
    
    # åˆ›å»º mock æ•°æ®é›†
    dataset = MockRGBTDataset(
        num_samples=10,
        num_frames=5,
        img_size=128,
        num_classes=7
    )
    dataloader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=0
    )
    
    print(f"\næ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"Batch å¤§å°: 2")
    print(f"Epoch æ•°: 3")
    
    # è®­ç»ƒå¾ªç¯
    model.train()
    total_losses = []
    
    try:
        for epoch in range(3):
            epoch_loss = 0
            start_time = time.time()
            
            for batch_idx, (rgb_frames, thermal_frames, targets) in enumerate(dataloader):
                rgb_frames = rgb_frames.to(device)
                thermal_frames = thermal_frames.to(device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                outputs = model(rgb_frames, thermal_frames)
                
                # ç®€åŒ–æŸå¤±è®¡ç®—
                loss = 0
                for t, output in enumerate(outputs):
                    # åˆ†ç±»æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    cls_pred = output['cls']  # (B, num_classes, H, W)
                    cls_target = targets[t]['cls'].to(device)  # (B, H, W)
                    
                    # ç¡®ä¿å°ºå¯¸åŒ¹é…
                    if cls_pred.shape[-2:] != cls_target.shape[-2:]:
                        cls_target = torch.nn.functional.interpolate(
                            cls_target.unsqueeze(1).float(),
                            size=cls_pred.shape[-2:],
                            mode='nearest'
                        ).squeeze(1).long()
                    
                    loss += nn.functional.cross_entropy(
                        cls_pred, 
                        cls_target.clamp(0, config.num_classes - 1),
                        ignore_index=-1
                    )
                    
                    # bbox æŸå¤±
                    loss += output['bbox'].mean() * 0.1
                
                loss = loss / len(outputs)
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                epoch_loss += loss.item()
            
            epoch_time = time.time() - start_time
            avg_loss = epoch_loss / len(dataloader)
            total_losses.append(avg_loss)
            
            print(f"  Epoch {epoch + 1}/3 - Loss: {avg_loss:.4f} - Time: {epoch_time:.2f}s")
        
        # éªŒè¯æŸå¤±æ˜¯å¦ä¸‹é™ï¼ˆæˆ–è‡³å°‘ç¨³å®šï¼‰
        if len(total_losses) >= 2:
            if total_losses[-1] <= total_losses[0] * 1.5:  # å…è®¸ä¸€äº›æ³¢åŠ¨
                print("\nâœ“ è®­ç»ƒå¾ªç¯æµ‹è¯•é€šè¿‡!")
                print(f"  æŸå¤±å˜åŒ–: {total_losses[0]:.4f} -> {total_losses[-1]:.4f}")
                return True
            else:
                print(f"\nâš  è­¦å‘Š: æŸå¤±ä¸Šå‡ {total_losses[0]:.4f} -> {total_losses[-1]:.4f}")
                return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œå› ä¸ºç½‘ç»œå¯ä»¥è¿è¡Œ
        
        return True
        
    except Exception as e:
        print(f"\nâœ— è®­ç»ƒå¾ªç¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("TLCFormer æ¨¡å‹éªŒè¯")
    print("=" * 60)
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    results = {}
    
    # æµ‹è¯• 1: ç‹¬ç«‹æ¨¡å—
    results['modules'] = test_individual_modules()
    
    # æµ‹è¯• 2: å‰å‘ä¼ æ’­
    success, model = test_full_model_forward()
    results['forward'] = success
    
    # æµ‹è¯• 3: åå‘ä¼ æ’­
    results['backward'] = test_backward_and_gradient()
    
    # æµ‹è¯• 4: è®­ç»ƒå¾ªç¯
    results['training'] = test_training_loop()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("éªŒè¯ç»“æœæ€»ç»“")
    print("=" * 60)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"  {test_name}: {status}")
        all_passed = all_passed and passed
    
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰éªŒè¯æµ‹è¯•é€šè¿‡!")
        print("\nTLCFormer æ ¸å¿ƒæ”¹è¿›å·²æˆåŠŸé›†æˆ:")
        print("  1. MADA (Motion-Aware Difference Attention)")
        print("  2. DLCM (Deep Local Contrast Module)")
        print("  3. Hybrid Energy-Preserving Mixer")
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print("=" * 60)
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
