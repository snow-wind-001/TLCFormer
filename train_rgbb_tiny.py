"""
ä½¿ç”¨RGBT-Tinyæ•°æ®é›†è®­ç»ƒOSFormer
é€‚é…7ç±»åˆ«å¤šç›®æ ‡æ£€æµ‹
"""

import os
import sys
import argparse
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.cuda.amp import GradScaler, autocast
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from datetime import datetime
import logging
from tqdm import tqdm
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.osformer import OSFormer, build_osformer
from datasets.rgbt_tiny_coco import RGBTTinyCOCODataset, collate_fn
from utils.loss import compute_loss
from utils.metrics import DetectionMetrics
from utils.target_utils import convert_targets_for_loss
from utils.visualize import visualize_detection_results, images_to_tensorboard_grid


class EarlyStopping:
    """
    æ—©é€€æœºåˆ¶
    
    å‚æ•°ï¼š
        patience (int): å®¹å¿çš„ epoch æ•°
        min_delta (float): æœ€å°æ”¹è¿›é‡
        mode (str): 'min' æˆ– 'max'
    """
    
    def __init__(self, patience=10, min_delta=0.0, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
        if mode == 'min':
            self.is_better = lambda current, best: current < best - min_delta
        else:
            self.is_better = lambda current, best: current > best + min_delta
    
    def __call__(self, current_score):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©é€€
        
        å‚æ•°ï¼š
            current_score: å½“å‰æŒ‡æ ‡å€¼
            
        è¿”å›ï¼š
            should_stop: æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
        """
        if self.best_score is None:
            self.best_score = current_score
            return False
        
        if self.is_better(current_score, self.best_score):
            # æœ‰æ”¹è¿›
            self.best_score = current_score
            self.counter = 0
            return False
        else:
            # æ²¡æœ‰æ”¹è¿›
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                return True
            return False
    
    def reset(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.counter = 0
        self.best_score = None
        self.early_stop = False


def build_scheduler(optimizer, warmup_epochs, total_epochs, steps_per_epoch):
    """æ„å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    warmup_steps = warmup_epochs * steps_per_epoch
    total_steps = total_epochs * steps_per_epoch
    
    def lr_lambda(step):
        if step < warmup_steps:
            # Linear warmup
            return step / warmup_steps
        else:
            # Cosine annealing
            progress = (step - warmup_steps) / (total_steps - warmup_steps)
            return 0.5 * (1 + np.cos(np.pi * progress))
    
    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    return scheduler


def setup_logging(log_dir):
    """è®¾ç½®æ—¥å¿—"""
    os.makedirs(log_dir, exist_ok=True)

    log_file = os.path.join(log_dir, f'train_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )

    return logging.getLogger(__name__)


def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config


def build_datasets(config):
    """æ„å»ºæ•°æ®é›†"""
    train_config = config['train']
    data_config = config['data']
    model_config = config['model']
    
    # è·å– tracking å’Œ frame_interval é…ç½®
    frame_interval = model_config.get('frame_interval', 1)
    tracking_config = data_config.get('tracking', {})

    # è®­ç»ƒæ•°æ®é›†
    train_dataset = RGBTTinyCOCODataset(
        root_dir=data_config['root_dir'],
        split='train',
        num_frames=model_config['num_frames'],
        frame_interval=frame_interval,  # æ–°å¢
        img_size=model_config['img_size'],
        modality=data_config.get('modality', 'both'),
        tracking_config=tracking_config  # æ–°å¢
    )

    # éªŒè¯æ•°æ®é›†
    val_dataset = RGBTTinyCOCODataset(
        root_dir=data_config['root_dir'],
        split='test',
        num_frames=model_config['num_frames'],
        frame_interval=frame_interval,  # æ–°å¢
        img_size=model_config['img_size'],
        modality=data_config.get('modality', 'both'),
        tracking_config=tracking_config  # æ–°å¢
    )

    return train_dataset, val_dataset


def build_dataloaders(train_dataset, val_dataset, config):
    """æ„å»ºæ•°æ®åŠ è½½å™¨"""
    train_config = config['train']
    data_config = config['data']

    train_loader = DataLoader(
        train_dataset,
        batch_size=train_config['batch_size'],
        shuffle=True,
        num_workers=data_config['num_workers'],
        collate_fn=collate_fn,
        pin_memory=True,
        drop_last=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=config['eval']['batch_size'],
        shuffle=False,
        num_workers=data_config['num_workers'],
        collate_fn=collate_fn,
        pin_memory=True
    )

    return train_loader, val_loader


def build_model(config):
    """æ„å»ºæ¨¡å‹"""
    model_config = config['model']

    model = build_osformer(
        num_frames=model_config['num_frames'],
        sample_frames=model_config['sample_frames'],
        img_size=model_config['img_size'],
        num_classes=model_config['num_classes'],
        embed_dim=model_config['embed_dim'],
        depths=model_config['depths'],
        use_doppler=model_config['use_doppler'],
        anchor_free=model_config['anchor_free'],
        dropout=model_config['dropout']
    )

    return model


def build_optimizer(model, config):
    """æ„å»ºä¼˜åŒ–å™¨"""
    train_config = config['train']

    # åˆ†å±‚è®¾ç½®æƒé‡è¡°å‡
    no_decay = ['bias', 'LayerNorm.weight']
    optimizer_grouped_parameters = [
        {
            'params': [p for n, p in model.named_parameters()
                      if not any(nd in n for nd in no_decay)],
            'weight_decay': train_config['weight_decay']
        },
        {
            'params': [p for n, p in model.named_parameters()
                      if any(nd in n for nd in no_decay)],
            'weight_decay': 0.0
        }
    ]

    optimizer = optim.AdamW(
        optimizer_grouped_parameters,
        lr=train_config['lr'],
        betas=train_config['betas']
    )

    return optimizer


def train_one_epoch(model, train_loader, optimizer, scheduler, scaler, device, config, epoch, writer=None):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()

    total_loss = 0
    loss_components = {
        'loss': 0,
        'cls_loss': 0,
        'bbox_loss': 0,
        'centerness_loss': 0,
        'offset_loss': 0
    }

    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')

    for batch_idx, batch in enumerate(pbar):
        # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
        rgb = batch['rgb'].to(device)  # (B, T, 3, H, W)
        thermal = batch['thermal'].to(device)  # (B, T, 1, H, W)
        targets_batch = batch['targets']
        
        # å‰å‘ä¼ æ’­ï¼ˆå…ˆæ¨ç†è·å–feature_sizeï¼‰
        with autocast(enabled=config['train']['amp']):
            predictions = model(rgb, thermal)  # List of dict, é•¿åº¦ä¸º T
            
            # ğŸ”¥ ä»å®é™…æ¨¡å‹è¾“å‡ºè·å–ç‰¹å¾å›¾å°ºå¯¸ï¼ˆstride=8ï¼Œå³640/8=80ï¼‰
            _, _, feature_size, _ = predictions[0]['cls'].shape  # ä½¿ç”¨å®é™…è¾“å‡ºå°ºå¯¸
            
            # è½¬æ¢ç›®æ ‡æ ¼å¼ï¼ˆä»æ•°æ®é›†æ ¼å¼è½¬æ¢ä¸ºæŸå¤±å‡½æ•°æ ¼å¼ï¼‰
            use_tracking = config['data'].get('tracking', {}).get('enabled', False)
            targets = convert_targets_for_loss(
                targets_batch,
                num_frames=config['model']['num_frames'],
                img_size=config['model']['img_size'],
                feature_size=feature_size,
                device=device,
                use_tracking_offset=use_tracking  # æ–°å¢
            )
            
            # è®¡ç®—æŸå¤±
            total_loss, loss_dict = compute_loss(predictions, targets, config['train']['loss_weights'])
            loss = total_loss
        
        # æ£€æµ‹ NaN/Infï¼Œå¦‚æœå‘ç°åˆ™è·³è¿‡æ­¤ batch
        if torch.isnan(loss) or torch.isinf(loss):
            logger.warning(f"NaN/Inf detected in loss at batch {batch_idx}, skipping this batch...")
            # è·³è¿‡æ­¤batchï¼Œä¸æ›´æ–°æ¢¯åº¦
            pbar.update(1)
            continue

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        
        if config['train']['amp']:
            scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            if config['train']['clip_grad'] > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(
                    model.parameters(),
                    config['train']['clip_grad']
                )
            
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            if config['train']['clip_grad'] > 0:
                torch.nn.utils.clip_grad_norm_(
                    model.parameters(),
                    config['train']['clip_grad']
                )
            
            optimizer.step()

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # ç»Ÿè®¡æŸå¤±
        # ğŸ”¥ ä¿®å¤ï¼šç´¯åŠ å½“å‰batchçš„losså€¼
        total_loss += loss.item()
        # ğŸ”¥ ä¿®å¤ï¼šç´¯åŠ loss_dictä¸­çš„å„åˆ†é‡å€¼ï¼ˆæ³¨æ„loss_dictå·²ç»æ˜¯itemå€¼ï¼‰
        for key in loss_components:
            if key in loss_dict:
                loss_components[key] += loss_dict[key]

        # è®°å½•åˆ° TensorBoard (æ¯ä¸ª batch)
        if writer is not None:
            global_step = epoch * len(train_loader) + batch_idx
            # æ€»æŸå¤±å’Œå­¦ä¹ ç‡
            writer.add_scalar('train/batch_loss', loss.item(), global_step)
            writer.add_scalar('train/learning_rate', optimizer.param_groups[0]['lr'], global_step)
            # å„ä¸ªæŸå¤±åˆ†é‡ï¼ˆæ¯100ä¸ªbatchè®°å½•ä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼‰
            if batch_idx % 100 == 0:
                writer.add_scalar('train/batch_cls_loss', loss_dict['cls_loss'], global_step)
                writer.add_scalar('train/batch_bbox_loss', loss_dict['bbox_loss'], global_step)
                writer.add_scalar('train/batch_centerness_loss', loss_dict['centerness_loss'], global_step)
                writer.add_scalar('train/batch_offset_loss', loss_dict['offset_loss'], global_step)

        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'lr': f'{optimizer.param_groups[0]["lr"]:.6f}'
        })

    # è®¡ç®—å¹³å‡æŸå¤±
    avg_loss = total_loss / len(train_loader)
    avg_components = {k: v / len(train_loader) for k, v in loss_components.items()}

    return avg_loss, avg_components


def visualize_epoch_results(model, dataloader, device, config, epoch, writer, split='train'):
    """
    åœ¨æ¯ä¸ªepochç»“æŸåå¯è§†åŒ–ä¸€äº›æ ·æœ¬
    
    å‚æ•°ï¼š
        model: æ¨¡å‹
        dataloader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        config: é…ç½®
        epoch: å½“å‰epoch
        writer: TensorBoard writer
        split: 'train' æˆ– 'val'
    """
    model.eval()
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªbatchè¿›è¡Œå¯è§†åŒ–
    import random
    batch_idx = random.randint(0, min(len(dataloader) - 1, 10))
    
    with torch.no_grad():
        for idx, batch in enumerate(dataloader):
            if idx != batch_idx:
                continue
            
            rgb = batch['rgb'].to(device)
            thermal = batch['thermal'].to(device)
            targets_batch = batch['targets']
            
            # å‰å‘ä¼ æ’­
            predictions = model(rgb, thermal)
            
            # å¯è§†åŒ–
            vis_images = visualize_detection_results(
                rgb, thermal, predictions, targets_batch,
                config['classes']['names'],
                score_thresh=config['eval'].get('score_thresh', 0.3),
                max_samples=4,
                mid_frame_only=True
            )
            
            # è½¬æ¢ä¸ºç½‘æ ¼å¹¶å†™å…¥TensorBoard
            if len(vis_images) > 0:
                grid = images_to_tensorboard_grid(vis_images, nrow=2)
                writer.add_image(f'{split}/predictions', grid, epoch)
            
            break
    
    model.train()


def compute_iou(boxes1, boxes2):
    """
    è®¡ç®—ä¸¤ç»„æ¡†çš„IoU
    boxes1: (N, 4) [x1, y1, x2, y2]
    boxes2: (M, 4) [x1, y1, x2, y2]
    è¿”å›: (N, M) IoUçŸ©é˜µ
    """
    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])
    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])
    
    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # (N, M, 2)
    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # (N, M, 2)
    
    wh = (rb - lt).clamp(min=0)  # (N, M, 2)
    inter = wh[:, :, 0] * wh[:, :, 1]  # (N, M)
    
    union = area1[:, None] + area2 - inter
    iou = inter / (union + 1e-6)
    
    return iou


def decode_predictions(predictions, img_size, feature_size, score_thresh=0.3, num_classes=7):
    """
    è§£ç é¢„æµ‹ç»“æœä¸ºè¾¹ç•Œæ¡†
    
    Args:
        predictions: dict with 'cls', 'bbox', 'centerness'
        img_size: åŸå›¾å°ºå¯¸ (640)
        feature_size: ç‰¹å¾å›¾å°ºå¯¸ (40)
        score_thresh: åˆ†æ•°é˜ˆå€¼
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        boxes: (N, 4) [x1, y1, x2, y2] åŸå›¾åæ ‡
        scores: (N,) ç½®ä¿¡åº¦
        labels: (N,) ç±»åˆ«ID
    """
    cls_pred = predictions['cls']  # (B, num_classes, H, W)
    bbox_pred = predictions['bbox']  # (B, 4, H, W)
    centerness_pred = predictions.get('centerness', None)  # (B, 1, H, W)
    
    B, C, H, W = cls_pred.shape
    device = cls_pred.device
    
    # è®¡ç®—stride
    stride = img_size / feature_size
    
    all_boxes = []
    all_scores = []
    all_labels = []
    
    for b in range(B):
        # å¯¹æ¯ä¸ªæ ·æœ¬è§£ç 
        cls_b = cls_pred[b]  # (num_classes, H, W)
        bbox_b = bbox_pred[b]  # (4, H, W)
        
        # åº”ç”¨sigmoidåˆ°åˆ†ç±»åˆ†æ•°
        scores_b = torch.sigmoid(cls_b)  # (num_classes+1, H, W)
        
        # ğŸ”¥ æ”¹è¿›ï¼šæ’é™¤èƒŒæ™¯ç±»ï¼ˆæœ€åä¸€ä¸ªé€šé“ï¼‰
        # åªè€ƒè™‘å‰num_classesä¸ªå‰æ™¯ç±»
        scores_b_fg = scores_b[:num_classes]  # (num_classes, H, W) å‰æ™¯ç±»
        
        # å¦‚æœæœ‰centernessï¼Œåº”ç”¨åˆ°åˆ†æ•°ä¸Š
        if centerness_pred is not None:
            centerness_b = torch.sigmoid(centerness_pred[b, 0])  # (H, W)
            scores_b_fg = scores_b_fg * centerness_b.unsqueeze(0)  # (num_classes, H, W)
        
        # æ‰¾åˆ°æ¯ä¸ªç±»åˆ«çš„æœ€å¤§åˆ†æ•°å’Œä½ç½®
        max_scores, _ = scores_b_fg.max(dim=0)  # (H, W)
        max_labels = scores_b_fg.argmax(dim=0)  # (H, W)
        
        # ç­›é€‰é«˜äºé˜ˆå€¼çš„ä½ç½®
        mask = max_scores > score_thresh
        
        if mask.sum() == 0:
            # æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡
            all_boxes.append(torch.zeros(0, 4, device=device))
            all_scores.append(torch.zeros(0, device=device))
            all_labels.append(torch.zeros(0, dtype=torch.long, device=device))
            continue
        
        # è·å–æœ‰æ•ˆä½ç½®çš„ç´¢å¼•
        valid_indices = mask.nonzero(as_tuple=False)  # (N, 2) [h, w]
        valid_scores = max_scores[mask]  # (N,)
        valid_labels = max_labels[mask]  # (N,)
        
        # è·å–å¯¹åº”çš„bboxé¢„æµ‹ (l, t, r, b)
        valid_bbox = bbox_pred[b, :, mask]  # (4, N)
        valid_bbox = valid_bbox.t()  # (N, 4)
        
        # è½¬æ¢FCOSæ ¼å¼ (l,t,r,b) åˆ° (x1,y1,x2,y2)
        h_idx = valid_indices[:, 0].float()
        w_idx = valid_indices[:, 1].float()
        
        # ç½‘æ ¼ä¸­å¿ƒåæ ‡ï¼ˆåŸå›¾åæ ‡ç³»ï¼‰
        center_x = (w_idx + 0.5) * stride
        center_y = (h_idx + 0.5) * stride
        
        # è½¬æ¢ä¸º x1, y1, x2, y2
        l, t, r, b = valid_bbox[:, 0], valid_bbox[:, 1], valid_bbox[:, 2], valid_bbox[:, 3]
        x1 = (center_x - l * stride).clamp(min=0, max=img_size)
        y1 = (center_y - t * stride).clamp(min=0, max=img_size)
        x2 = (center_x + r * stride).clamp(min=0, max=img_size)
        y2 = (center_y + b * stride).clamp(min=0, max=img_size)
        
        boxes_b = torch.stack([x1, y1, x2, y2], dim=1)  # (N, 4)
        
        # âœ… æ·»åŠ  NMS
        if len(boxes_b) > 0:
            try:
                from torchvision.ops import nms
                keep_indices = nms(boxes_b, valid_scores, iou_threshold=0.5)
                boxes_b = boxes_b[keep_indices]
                valid_scores = valid_scores[keep_indices]
                valid_labels = valid_labels[keep_indices]
            except Exception as e:
                # NMSå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ
                pass
        
        all_boxes.append(boxes_b)
        all_scores.append(valid_scores)
        all_labels.append(valid_labels)
    
    return all_boxes, all_scores, all_labels


def evaluate(model, val_loader, device, config, class_names):
    """
    è¯„ä¼°æ¨¡å‹ - è®¡ç®—çœŸå®çš„mAP, Precision, Recallç­‰æŒ‡æ ‡
    ä½¿ç”¨IoUåŒ¹é…å’ŒAPè®¡ç®—
    """
    model.eval()
    
    # å­˜å‚¨æ‰€æœ‰é¢„æµ‹å’ŒGTï¼Œç”¨äºè®¡ç®—mAP
    all_predictions = []  # List of dicts: {'boxes', 'scores', 'labels'}
    all_ground_truths = []  # List of dicts: {'boxes', 'labels'}
    
    total_val_loss = 0.0
    loss_components_val = {'cls_loss': 0.0, 'bbox_loss': 0.0, 'centerness_loss': 0.0, 'offset_loss': 0.0}
    
    img_size = config['model']['img_size']
    # ğŸ”¥ ä¿®æ”¹ï¼šstride=8ï¼ˆNeckå·²ä¸Šé‡‡æ ·ï¼‰
    feature_size = img_size // 8  # stride=8 (640/8=80)
    score_thresh = config['eval'].get('score_thresh', 0.3)
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc='Evaluating'):
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            rgb = batch['rgb'].to(device)
            thermal = batch['thermal'].to(device)
            targets_batch = batch['targets']
            
            # å‰å‘ä¼ æ’­
            predictions = model(rgb, thermal)  # List of dict, length T
            
            # è®¡ç®—éªŒè¯æŸå¤±
            use_tracking = config['data'].get('tracking', {}).get('enabled', False)
            targets = convert_targets_for_loss(
                targets_batch,
                num_frames=config['model']['num_frames'],
                img_size=img_size,
                feature_size=feature_size,
                device=device,
                use_tracking_offset=use_tracking  # æ–°å¢
            )
            
            total_loss, loss_dict = compute_loss(
                predictions, targets, config['train']['loss_weights']
            )
            total_val_loss += total_loss.item()
            for key in loss_components_val:
                if key in loss_dict:
                    loss_components_val[key] += loss_dict[key]
            
            # è§£ç é¢„æµ‹ç»“æœï¼ˆä½¿ç”¨ä¸­é—´å¸§ï¼‰
            mid_frame = len(predictions) // 2
            pred_frame = predictions[mid_frame]
            
            # è§£ç ä¸ºè¾¹ç•Œæ¡†
            boxes_list, scores_list, labels_list = decode_predictions(
                pred_frame, img_size, feature_size, score_thresh, config['model']['num_classes']
            )
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå½’ä¸€åŒ–é¢„æµ‹åæ ‡åˆ° [0, 1] ä»¥åŒ¹é…GT
            # GTæ˜¯å½’ä¸€åŒ–çš„[x1, y1, x2, y2]ï¼Œé¢„æµ‹æ˜¯åƒç´ åæ ‡ï¼Œéœ€è¦å½’ä¸€åŒ–
            for b_idx in range(len(boxes_list)):
                if len(boxes_list[b_idx]) > 0:
                    boxes_list[b_idx] = boxes_list[b_idx] / img_size
            
            # æ”¶é›†é¢„æµ‹å’ŒGT
            B = len(boxes_list)
            for b in range(B):
                # é¢„æµ‹ï¼ˆå·²å½’ä¸€åŒ–ï¼‰
                all_predictions.append({
                    'boxes': boxes_list[b].cpu(),  # (N, 4) [x1, y1, x2, y2] å½’ä¸€åŒ–
                    'scores': scores_list[b].cpu(),  # (N,)
                    'labels': labels_list[b].cpu()  # (N,)
                })
                
                # Ground Truth
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šGTå·²ç»æ˜¯[x1, y1, x2, y2]å½’ä¸€åŒ–æ ¼å¼ï¼Œæ— éœ€è½¬æ¢ï¼
                gt_boxes = targets_batch[b]['boxes']  # (M, 4) [x1, y1, x2, y2] å½’ä¸€åŒ– âœ…
                gt_labels = targets_batch[b]['labels']  # (M,)
                
                # ç›´æ¥ä½¿ç”¨GTï¼Œæ— éœ€ä»»ä½•è½¬æ¢
                all_ground_truths.append({
                    'boxes': gt_boxes,  # (M, 4) [x1, y1, x2, y2] å½’ä¸€åŒ–
                    'labels': gt_labels  # (M,)
                })
    
    # è®¡ç®—å¹³å‡æŸå¤±
    avg_val_loss = total_val_loss / len(val_loader)
    for key in loss_components_val:
        loss_components_val[key] /= len(val_loader)
    
    # è®¡ç®—mAP
    map50, map75, precision, recall = compute_map(
        all_predictions, all_ground_truths, 
        iou_thresholds=[0.5, 0.75],
        num_classes=config['model']['num_classes']
    )
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_pred = sum(len(p['boxes']) for p in all_predictions)
    total_gt = sum(len(g['boxes']) for g in all_ground_truths)
    avg_pred_per_image = total_pred / len(all_predictions) if len(all_predictions) > 0 else 0
    avg_gt_per_image = total_gt / len(all_ground_truths) if len(all_ground_truths) > 0 else 0
    
    results = {
        # çœŸå®mAPæŒ‡æ ‡
        'map50': map50,
        'map75': map75,
        'map50_95': (map50 + map75) / 2,  # ç®€åŒ–çš„mAP50-95
        
        # ç²¾åº¦å’Œå¬å›ç‡
        'precision': precision,
        'recall': recall,
        
        # éªŒè¯æŸå¤±
        'val_loss': avg_val_loss,
        'val_cls_loss': loss_components_val['cls_loss'],
        'val_bbox_loss': loss_components_val['bbox_loss'],
        'val_centerness_loss': loss_components_val['centerness_loss'],
        'val_offset_loss': loss_components_val['offset_loss'],
        
        # ç»Ÿè®¡ä¿¡æ¯
        'avg_pred_per_image': avg_pred_per_image,
        'avg_gt_per_image': avg_gt_per_image,
        'total_samples': len(all_predictions)
    }
    
    return results


def compute_map(predictions, ground_truths, iou_thresholds=[0.5], num_classes=7):
    """
    è®¡ç®—mAP
    
    Args:
        predictions: List of dicts with 'boxes', 'scores', 'labels'
        ground_truths: List of dicts with 'boxes', 'labels'
        iou_thresholds: List of IoU thresholds
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        map50, map75, precision, recall
    """
    aps = []
    all_precisions = []
    all_recalls = []
    
    for iou_thresh in iou_thresholds:
        # å¯¹æ¯ä¸ªç±»åˆ«è®¡ç®—AP
        class_aps = []
        for cls_id in range(num_classes):
            # æ”¶é›†è¯¥ç±»åˆ«çš„æ‰€æœ‰é¢„æµ‹å’ŒGT
            cls_preds = []
            cls_gts = []
            
            for pred, gt in zip(predictions, ground_truths):
                # ç­›é€‰è¯¥ç±»åˆ«çš„é¢„æµ‹
                cls_mask = pred['labels'] == cls_id
                if cls_mask.sum() > 0:
                    cls_preds.append({
                        'boxes': pred['boxes'][cls_mask],
                        'scores': pred['scores'][cls_mask]
                    })
                else:
                    cls_preds.append({'boxes': torch.zeros(0, 4), 'scores': torch.zeros(0)})
                
                # ç­›é€‰è¯¥ç±»åˆ«çš„GT
                gt_cls_mask = gt['labels'] == cls_id
                if gt_cls_mask.sum() > 0:
                    cls_gts.append({'boxes': gt['boxes'][gt_cls_mask]})
                else:
                    cls_gts.append({'boxes': torch.zeros(0, 4)})
            
            # è®¡ç®—è¯¥ç±»åˆ«çš„AP
            ap, prec, rec = compute_class_ap(cls_preds, cls_gts, iou_thresh)
            class_aps.append(ap)
            all_precisions.append(prec)
            all_recalls.append(rec)
        
        # å¹³å‡æ‰€æœ‰ç±»åˆ«çš„AP
        aps.append(np.mean(class_aps) if len(class_aps) > 0 else 0.0)
    
    # è¿”å›mAP@50 and mAP@75
    map50 = aps[0] if len(aps) > 0 else 0.0
    map75 = aps[1] if len(aps) > 1 else 0.0
    
    # å¹³å‡precisionå’Œrecall
    avg_precision = np.mean(all_precisions) if len(all_precisions) > 0 else 0.0
    avg_recall = np.mean(all_recalls) if len(all_recalls) > 0 else 0.0
    
    return map50, map75, avg_precision, avg_recall


def compute_class_ap(predictions, ground_truths, iou_threshold=0.5):
    """
    è®¡ç®—å•ä¸ªç±»åˆ«çš„AP
    
    Returns:
        ap, precision, recall
    """
    # æ”¶é›†æ‰€æœ‰é¢„æµ‹æ¡†å’Œåˆ†æ•°
    all_boxes = []
    all_scores = []
    all_image_ids = []
    
    for img_id, pred in enumerate(predictions):
        if len(pred['boxes']) > 0:
            all_boxes.append(pred['boxes'])
            all_scores.append(pred['scores'])
            all_image_ids.extend([img_id] * len(pred['boxes']))
    
    if len(all_boxes) == 0:
        return 0.0, 0.0, 0.0
    
    all_boxes = torch.cat(all_boxes, dim=0)  # (N, 4)
    all_scores = torch.cat(all_scores, dim=0)  # (N,)
    all_image_ids = torch.tensor(all_image_ids)
    
    # æŒ‰åˆ†æ•°æ’åº
    sorted_indices = torch.argsort(all_scores, descending=True)
    all_boxes = all_boxes[sorted_indices]
    all_scores = all_scores[sorted_indices]
    all_image_ids = all_image_ids[sorted_indices]
    
    # ç»Ÿè®¡GTæ•°é‡
    num_gts = sum(len(gt['boxes']) for gt in ground_truths)
    
    if num_gts == 0:
        return 0.0, 0.0, 0.0
    
    # åŒ¹é…é¢„æµ‹å’ŒGT
    tp = torch.zeros(len(all_boxes))
    fp = torch.zeros(len(all_boxes))
    
    # è®°å½•æ¯ä¸ªGTæ˜¯å¦å·²è¢«åŒ¹é…
    gt_matched = [torch.zeros(len(gt['boxes']), dtype=torch.bool) for gt in ground_truths]
    
    for i in range(len(all_boxes)):
        img_id = all_image_ids[i].item()
        pred_box = all_boxes[i:i+1]  # (1, 4)
        
        gt_boxes = ground_truths[img_id]['boxes']
        
        if len(gt_boxes) == 0:
            fp[i] = 1
            continue
        
        # è®¡ç®—IoU
        ious = compute_iou(pred_box, gt_boxes)  # (1, M)
        max_iou, max_idx = ious.max(dim=1)
        max_iou = max_iou.item()
        max_idx = max_idx.item()
        
        if max_iou >= iou_threshold:
            if not gt_matched[img_id][max_idx]:
                tp[i] = 1
                gt_matched[img_id][max_idx] = True
            else:
                fp[i] = 1  # è¯¥GTå·²è¢«åŒ¹é…
        else:
            fp[i] = 1
    
    # è®¡ç®—ç´¯ç§¯TPå’ŒFP
    tp_cumsum = torch.cumsum(tp, dim=0)
    fp_cumsum = torch.cumsum(fp, dim=0)
    
    # è®¡ç®—precisionå’Œrecall
    precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
    recalls = tp_cumsum / num_gts
    
    # è®¡ç®—AP (ä½¿ç”¨11ç‚¹æ’å€¼)
    ap = 0.0
    for t in torch.linspace(0, 1, 11):
        mask = recalls >= t
        if mask.sum() > 0:
            ap += precisions[mask].max().item()
    ap /= 11
    
    # è¿”å›æœ€ç»ˆçš„precisionå’Œrecall
    final_precision = precisions[-1].item() if len(precisions) > 0 else 0.0
    final_recall = recalls[-1].item() if len(recalls) > 0 else 0.0
    
    return ap, final_precision, final_recall


def save_checkpoint(model, optimizer, scheduler, epoch, loss, config, save_path):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'loss': loss,
        'config': config
    }

    torch.save(checkpoint, save_path)
    print(f'Checkpoint saved to {save_path}')


def find_best_checkpoint(checkpoint_dir):
    """
    è‡ªåŠ¨æŸ¥æ‰¾æ£€æŸ¥ç‚¹ç›®å½•ä¸­çš„æœ€ä½³æ¨¡å‹
    
    Returns:
        best_checkpoint_path: str or None
    """
    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')
    if os.path.exists(best_model_path):
        return best_model_path
    return None


def find_latest_checkpoint(checkpoint_dir):
    """
    è‡ªåŠ¨æŸ¥æ‰¾æ£€æŸ¥ç‚¹ç›®å½•ä¸­çš„æœ€æ–°epochæ¨¡å‹
    
    Returns:
        latest_checkpoint_path: str or None
    """
    import glob
    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'epoch_*.pth'))
    if not checkpoint_files:
        return None
    
    # æŒ‰epochæ•°å­—æ’åº
    def extract_epoch(path):
        basename = os.path.basename(path)
        # epoch_50.pth -> 50
        epoch_str = basename.replace('epoch_', '').replace('.pth', '')
        try:
            return int(epoch_str)
        except:
            return -1
    
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0] if checkpoint_files else None


def main():
    parser = argparse.ArgumentParser(description='Train OSFormer on RGBT-Tiny dataset')
    parser.add_argument('--config', type=str,
                       default='./configs/rgbt_tiny_config.yaml',
                       help='Path to config file')
    parser.add_argument('--resume', type=str, default=None,
                       help='Path to checkpoint to resume from. Special values: "best", "latest", "auto"')
    parser.add_argument('--resume_from_best', action='store_true',
                       help='Automatically resume from best_model.pth in checkpoint dir')
    parser.add_argument('--resume_from_latest', action='store_true',
                       help='Automatically resume from latest epoch checkpoint')
    parser.add_argument('--reset_optimizer', action='store_true',
                       help='Reset optimizer and scheduler when resuming (useful for fine-tuning)')
    parser.add_argument('--reset_epochs', action='store_true',
                       help='Reset epoch counter to 0 when resuming (for fine-tuning)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='Number of epochs (override config)')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='Batch size (override config)')
    parser.add_argument('--lr', type=float, default=None,
                       help='Learning rate (override config)')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use')
    parser.add_argument('--amp', action='store_true',
                       help='Use mixed precision training')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = load_config(args.config)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.epochs:
        config['train']['num_epochs'] = args.epochs
    if args.batch_size:
        config['train']['batch_size'] = args.batch_size
    if args.lr:
        config['train']['lr'] = args.lr
    if args.amp:
        config['train']['amp'] = True

    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f'Using device: {device}')

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(config['save']['log_dir'])
    logger.info(f'Starting training with config: {args.config}')

    # æ„å»ºæ•°æ®é›†
    logger.info('Building datasets...')
    train_dataset, val_dataset = build_datasets(config)
    logger.info(f'Train dataset: {len(train_dataset)} samples')
    logger.info(f'Val dataset: {len(val_dataset)} samples')

    # æ„å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = build_dataloaders(train_dataset, val_dataset, config)

    # æ„å»ºæ¨¡å‹
    logger.info('Building model...')
    model = build_model(config)
    model = model.to(device)

    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f'Model parameters: {total_params:,} total, {trainable_params:,} trainable')

    # æ„å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = build_optimizer(model, config)
    steps_per_epoch = len(train_loader)
    scheduler = build_scheduler(
        optimizer, 
        warmup_epochs=config['train'].get('warmup_epochs', 5),
        total_epochs=config['train']['num_epochs'],
        steps_per_epoch=steps_per_epoch
    )

    # æ··åˆç²¾åº¦è®­ç»ƒ
    if config['train']['amp']:
        try:
            from torch.amp import GradScaler as NewGradScaler
            scaler = NewGradScaler('cuda')
        except (ImportError, AttributeError):
            # Fallback for older PyTorch versions
            scaler = GradScaler()
    else:
        scaler = None

    # åˆ›å»º TensorBoard writer
    tensorboard_dir = config['save'].get('tensorboard_dir', './runs/rgbt_tiny')
    os.makedirs(tensorboard_dir, exist_ok=True)
    writer = SummaryWriter(log_dir=tensorboard_dir)
    logger.info(f'TensorBoard logs will be saved to: {tensorboard_dir}')
    
    # è®°å½•é…ç½®ä¿¡æ¯åˆ°TensorBoard
    writer.add_text('config/loss_function', 'âœ… CIoU Loss (upgraded from L1)', 0)
    writer.add_text('config/loss_weights', str(config['train']['loss_weights']), 0)
    writer.add_text('config/model', f"Doppler={config['model']['use_doppler']}, Classes={config['model']['num_classes']}", 0)

    # åˆå§‹åŒ–æ—©é€€æœºåˆ¶
    early_stopping = None
    if config.get('early_stopping', {}).get('enabled', False):
        early_stopping = EarlyStopping(
            patience=config['early_stopping'].get('patience', 15),
            min_delta=config['early_stopping'].get('min_delta', 0.001),
            mode=config['early_stopping'].get('mode', 'max')
        )
        logger.info(f'Early stopping enabled with patience={early_stopping.patience}')

    # æ¢å¤è®­ç»ƒ
    start_epoch = 0
    best_metric_name = config['save'].get('best_metric', 'map50')
    best_epoch = 0
    
    # åˆå§‹åŒ– best_metric (æ ¹æ®æŒ‡æ ‡ç±»å‹å†³å®šåˆå§‹å€¼)
    if best_metric_name in ['loss', 'val_loss']:
        best_metric = float('inf')  # Lossç±»æŒ‡æ ‡è¶Šå°è¶Šå¥½
        best_mode = 'min'
    else:
        best_metric = 0.0  # mAPç±»æŒ‡æ ‡è¶Šå¤§è¶Šå¥½
        best_mode = 'max'
    
    logger.info(f'Model selection metric: {best_metric_name} (mode: {best_mode})')

    # ==================== æ™ºèƒ½æ¢å¤è®­ç»ƒ ====================
    resume_path = None
    
    # ç¡®å®šè¦æ¢å¤çš„checkpointè·¯å¾„
    if args.resume_from_best:
        resume_path = find_best_checkpoint(config['save']['checkpoint_dir'])
        if resume_path:
            logger.info(f'ğŸ” Found best model: {resume_path}')
        else:
            logger.warning('âŒ No best_model.pth found in checkpoint directory')
    
    elif args.resume_from_latest:
        resume_path = find_latest_checkpoint(config['save']['checkpoint_dir'])
        if resume_path:
            logger.info(f'ğŸ” Found latest checkpoint: {resume_path}')
        else:
            logger.warning('âŒ No epoch checkpoints found in checkpoint directory')
    
    elif args.resume:
        # å¤„ç†ç‰¹æ®Šå€¼
        if args.resume.lower() == 'best':
            resume_path = find_best_checkpoint(config['save']['checkpoint_dir'])
            if not resume_path:
                logger.warning('âŒ No best_model.pth found, will train from scratch')
        elif args.resume.lower() == 'latest':
            resume_path = find_latest_checkpoint(config['save']['checkpoint_dir'])
            if not resume_path:
                logger.warning('âŒ No epoch checkpoints found, will train from scratch')
        elif args.resume.lower() == 'auto':
            # è‡ªåŠ¨é€‰æ‹©ï¼šä¼˜å…ˆbestï¼Œå…¶æ¬¡latest
            resume_path = find_best_checkpoint(config['save']['checkpoint_dir'])
            if not resume_path:
                resume_path = find_latest_checkpoint(config['save']['checkpoint_dir'])
            if resume_path:
                logger.info(f'ğŸ” Auto-selected checkpoint: {resume_path}')
            else:
                logger.warning('âŒ No checkpoints found, will train from scratch')
        else:
            # ç›´æ¥æŒ‡å®šçš„è·¯å¾„
            resume_path = args.resume
    
    # åŠ è½½checkpoint
    if resume_path and os.path.exists(resume_path):
        logger.info('=' * 60)
        logger.info('ğŸ“¥ LOADING CHECKPOINT')
        logger.info('=' * 60)
        
        try:
            checkpoint = torch.load(resume_path, map_location=device)
            
            # åŠ è½½æ¨¡å‹æƒé‡
            model.load_state_dict(checkpoint['model_state_dict'])
            logger.info('âœ… Model weights loaded')
            
            # åŠ è½½ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ï¼ˆé™¤éæŒ‡å®šresetï¼‰
            if not args.reset_optimizer:
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                logger.info('âœ… Optimizer and scheduler loaded')
            else:
                logger.info('âš ï¸  Optimizer and scheduler reset (fine-tuning mode)')
            
            # åŠ è½½epochä¿¡æ¯ï¼ˆé™¤éæŒ‡å®šresetï¼‰
            if not args.reset_epochs:
                start_epoch = checkpoint['epoch'] + 1
                logger.info(f'âœ… Will resume from epoch {start_epoch}')
            else:
                start_epoch = 0
                logger.info('âš ï¸  Epoch counter reset to 0 (fine-tuning mode)')
            
            # åŠ è½½æœ€ä½³æŒ‡æ ‡ä¿¡æ¯
            if 'loss' in checkpoint and isinstance(checkpoint['loss'], dict):
                loss_info = checkpoint['loss']
                best_metric = loss_info.get('best_metric', best_metric)
                best_epoch = loss_info.get('best_epoch', 0)
                saved_metric_name = loss_info.get('best_metric_name', best_metric_name)
                
                if saved_metric_name == best_metric_name:
                    logger.info(f'âœ… Best metric loaded: {best_metric_name}={best_metric:.4f} (epoch {best_epoch})')
                else:
                    logger.warning(f'âš ï¸  Metric name mismatch: saved={saved_metric_name}, current={best_metric_name}')
                    logger.warning(f'   Will use saved best_metric value but may not be comparable')
            
            # æ˜¾ç¤ºcheckpointè¯¦ç»†ä¿¡æ¯
            logger.info('ğŸ“Š Checkpoint Info:')
            logger.info(f'  Checkpoint file:  {resume_path}')
            logger.info(f'  Saved epoch:      {checkpoint.get("epoch", "N/A")}')
            logger.info(f'  Resume from:      Epoch {start_epoch}')
            logger.info(f'  Best metric:      {best_metric_name}={best_metric:.4f} (Epoch {best_epoch})')
            
            if 'loss' in checkpoint and isinstance(checkpoint['loss'], dict):
                if 'val_results' in checkpoint['loss']:
                    val_res = checkpoint['loss']['val_results']
                    logger.info(f'  Last val mAP50:   {val_res.get("map50", 0):.4f}')
                    logger.info(f'  Last val loss:    {val_res.get("val_loss", 0):.4f}')
            
            logger.info('=' * 60)
            
        except Exception as e:
            logger.error(f'âŒ Failed to load checkpoint: {e}')
            logger.warning('Will train from scratch')
            import traceback
            traceback.print_exc()
    
    elif resume_path:
        logger.warning(f'âŒ Checkpoint not found: {resume_path}')
        logger.warning('Will train from scratch')

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save']['checkpoint_dir'], exist_ok=True)

    # è®­ç»ƒå¾ªç¯
    logger.info('Starting training...')

    for epoch in range(start_epoch, config['train']['num_epochs']):
        logger.info(f'Epoch {epoch}/{config["train"]["num_epochs"]}')

        # è®­ç»ƒ
        train_loss, loss_components = train_one_epoch(
            model, train_loader, optimizer, scheduler,
            scaler, device, config, epoch, writer
        )

        # ğŸ”¥ ä¿®å¤ï¼šæ›´æ¸…æ™°çš„æŸå¤±æ‰“å°æ ¼å¼
        logger.info(f'ğŸ“Š Train Loss: {train_loss:.4f}')
        logger.info(f'   â”œâ”€ Total Loss:      {loss_components["loss"]:.4f}')
        logger.info(f'   â”œâ”€ Cls Loss:        {loss_components["cls_loss"]:.6f}')
        logger.info(f'   â”œâ”€ BBox Loss:       {loss_components["bbox_loss"]:.4f}')
        logger.info(f'   â”œâ”€ Centerness Loss: {loss_components["centerness_loss"]:.4f}')
        logger.info(f'   â””â”€ Offset Loss:     {loss_components["offset_loss"]:.6f}')

        # è®°å½•è®­ç»ƒæŸå¤±åˆ° TensorBoard
        writer.add_scalar('epoch/train_loss', train_loss, epoch)
        for key, value in loss_components.items():
            writer.add_scalar(f'epoch/train_{key}', value, epoch)

        # å¯è§†åŒ–è®­ç»ƒæ ·æœ¬ï¼ˆæ¯ä¸ªepochï¼‰
        if config.get('visualize', {}).get('enabled', True):
            try:
                logger.info('ç”Ÿæˆå¯è§†åŒ–ç»“æœ...')
                visualize_epoch_results(
                    model, train_loader, device, config, epoch, writer, 'train'
                )
            except Exception as e:
                logger.warning(f'å¯è§†åŒ–å¤±è´¥: {e}')

        # ==================== è¯„ä¼°é˜¶æ®µ ====================
        val_results = None
        if (epoch + 1) % config['eval']['eval_interval'] == 0:
            logger.info('=' * 60)
            logger.info('ğŸ” Starting Evaluation...')
            
            val_results = evaluate(
                model, val_loader, device, config,
                config['classes']['names']
            )

            # ğŸ”¥ æ”¹è¿›ï¼šæ›´æ¸…æ™°çªå‡ºçš„éªŒè¯ç»“æœæ‰“å°
            logger.info('=' * 60)
            logger.info('ğŸ“Š VALIDATION RESULTS ğŸ“Š')
            logger.info('=' * 60)
            logger.info('ğŸ¯ Detection Metrics:')
            logger.info(f'   â”œâ”€ mAP@50:     {val_results["map50"]:.4f} â­â­â­')
            logger.info(f'   â”œâ”€ mAP@75:     {val_results["map75"]:.4f}')
            logger.info(f'   â”œâ”€ mAP@50-95:  {val_results["map50_95"]:.4f}')
            logger.info(f'   â”œâ”€ Precision:  {val_results["precision"]:.4f}')
            logger.info(f'   â””â”€ Recall:     {val_results["recall"]:.4f}')
            logger.info('')
            logger.info('ğŸ“‰ Validation Loss:')
            logger.info(f'   â”œâ”€ Total:      {val_results["val_loss"]:.4f}')
            logger.info(f'   â”œâ”€ Cls:        {val_results["val_cls_loss"]:.6f}')
            logger.info(f'   â”œâ”€ BBox:       {val_results["val_bbox_loss"]:.4f}')
            logger.info(f'   â”œâ”€ Centerness: {val_results["val_centerness_loss"]:.4f}')
            logger.info(f'   â””â”€ Offset:     {val_results["val_offset_loss"]:.6f}')
            logger.info('')
            logger.info('ğŸ“ˆ Statistics:')
            logger.info(f'   â”œâ”€ Avg Pred/Img: {val_results["avg_pred_per_image"]:.2f}')
            logger.info(f'   â””â”€ Avg GT/Img:   {val_results["avg_gt_per_image"]:.2f}')
            logger.info('=' * 60)

            # ğŸ”¥ æ”¹è¿›ï¼šè®°å½•æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡åˆ° TensorBoardï¼ŒæŒ‰ç±»åˆ«åˆ†ç»„
            # 1. mAPæŒ‡æ ‡ï¼ˆé‡ç‚¹çªå‡ºï¼‰
            writer.add_scalar('mAP/mAP@50', val_results['map50'], epoch)
            writer.add_scalar('mAP/mAP@75', val_results['map75'], epoch)
            writer.add_scalar('mAP/mAP@50-95', val_results['map50_95'], epoch)
            
            # 2. Precision & Recall
            writer.add_scalar('metrics/Precision', val_results['precision'], epoch)
            writer.add_scalar('metrics/Recall', val_results['recall'], epoch)
            
            # 3. Validation Loss
            writer.add_scalar('val_loss/total', val_results['val_loss'], epoch)
            writer.add_scalar('val_loss/cls', val_results['val_cls_loss'], epoch)
            writer.add_scalar('val_loss/bbox', val_results['val_bbox_loss'], epoch)
            writer.add_scalar('val_loss/centerness', val_results['val_centerness_loss'], epoch)
            writer.add_scalar('val_loss/offset', val_results['val_offset_loss'], epoch)
            
            # 4. Statistics
            writer.add_scalar('stats/avg_pred_per_image', val_results['avg_pred_per_image'], epoch)
            writer.add_scalar('stats/avg_gt_per_image', val_results['avg_gt_per_image'], epoch)
            
            # 5. ä¿æŒåŸæœ‰çš„é€šç”¨è®°å½•ï¼ˆå…¼å®¹æ€§ï¼‰
            for key, value in val_results.items():
                if isinstance(value, (int, float)):
                    writer.add_scalar(f'epoch/val_{key}', value, epoch)
            
            # å¯è§†åŒ–éªŒè¯æ ·æœ¬
            if config.get('visualize', {}).get('enabled', True):
                try:
                    visualize_epoch_results(
                        model, val_loader, device, config, epoch, writer, 'val'
                    )
                except Exception as e:
                    logger.warning(f'éªŒè¯é›†å¯è§†åŒ–å¤±è´¥: {e}')

            # ==================== æœ€ä½³æ¨¡å‹ä¿å­˜ ====================
            current_metric = val_results.get(best_metric_name, 0.0)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            is_best = False
            if best_mode == 'min':
                is_best = current_metric < best_metric
            else:  # 'max'
                is_best = current_metric > best_metric
            
            if is_best and config['save'].get('save_best', True):
                old_best = best_metric
                best_metric = current_metric
                best_epoch = epoch
                
                best_checkpoint_path = os.path.join(
                    config['save']['checkpoint_dir'], 'best_model.pth'
                )
                save_checkpoint(
                    model, optimizer, scheduler, epoch,
                    {
                        'val_results': val_results,
                        'best_metric': best_metric,
                        'best_epoch': best_epoch,
                        'best_metric_name': best_metric_name
                    },
                    config, best_checkpoint_path
                )
                
                logger.info('=' * 60)
                logger.info('âœ¨ NEW BEST MODEL SAVED!')
                logger.info(f'  Metric:       {best_metric_name}')
                logger.info(f'  Previous:     {old_best:.4f}')
                logger.info(f'  Current:      {best_metric:.4f} â¬†ï¸')
                logger.info(f'  Improvement:  +{(best_metric - old_best):.4f}')
                logger.info(f'  Saved to:     {best_checkpoint_path}')
                logger.info('=' * 60)
                
                writer.add_text(
                    'best_model', 
                    f'Epoch {epoch}: {best_metric_name}={best_metric:.4f} (improved by {(best_metric - old_best):.4f})', 
                    epoch
                )
                writer.add_scalar('epoch/best_metric', best_metric, epoch)
            else:
                logger.info(f'  Current {best_metric_name}: {current_metric:.4f}')
                logger.info(f'  Best {best_metric_name}:    {best_metric:.4f} (Epoch {best_epoch})')
                logger.info(f'  No improvement.')
            
            # ==================== æ—©åœæ£€æŸ¥ ====================
            if early_stopping is not None:
                # ä½¿ç”¨ä¸æ¨¡å‹ä¿å­˜ç›¸åŒçš„æŒ‡æ ‡è¿›è¡Œæ—©åœåˆ¤æ–­
                should_stop = early_stopping(current_metric)
                
                if should_stop:
                    logger.info('=' * 60)
                    logger.info('ğŸ›‘ EARLY STOPPING TRIGGERED')
                    logger.info(f'  Reason:       No improvement for {early_stopping.patience} epochs')
                    logger.info(f'  Stopped at:   Epoch {epoch}')
                    logger.info(f'  Best metric:  {best_metric_name}={best_metric:.4f} (Epoch {best_epoch})')
                    logger.info(f'  Total epochs: {epoch - start_epoch + 1}/{config["train"]["num_epochs"]}')
                    logger.info('=' * 60)
                    
                    writer.add_text(
                        'training', 
                        f'Early stopped at epoch {epoch}. Best {best_metric_name}: {best_metric:.4f} at epoch {best_epoch}', 
                        epoch
                    )
                    break
                else:
                    patience_left = early_stopping.patience - early_stopping.counter
                    logger.info(f'  Early stopping: {patience_left} epochs left before stopping')
            
            logger.info('=' * 60)

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % config['save']['save_interval'] == 0:
            checkpoint_path = os.path.join(
                config['save']['checkpoint_dir'], f'epoch_{epoch}.pth'
            )
            save_checkpoint(
                model, optimizer, scheduler, epoch,
                {'train_loss': train_loss, 'loss_components': loss_components},
                config, checkpoint_path
            )
            logger.info(f'ğŸ’¾ Checkpoint saved: epoch_{epoch}.pth')

    # ==================== è®­ç»ƒç»“æŸ ====================
    writer.close()
    
    logger.info('=' * 60)
    logger.info('ğŸ‰ TRAINING COMPLETED!')
    logger.info('=' * 60)
    logger.info('ğŸ“Š Final Statistics:')
    logger.info(f'  Total Epochs:     {epoch - start_epoch + 1}/{config["train"]["num_epochs"]}')
    logger.info(f'  Best Metric:      {best_metric_name}')
    logger.info(f'  Best Value:       {best_metric:.4f}')
    logger.info(f'  Best Epoch:       {best_epoch}')
    logger.info(f'  Final Train Loss: {train_loss:.4f}')
    if val_results:
        logger.info(f'  Final Val Loss:   {val_results["val_loss"]:.4f}')
    logger.info('=' * 60)
    logger.info('ğŸ“ Saved Files:')
    logger.info(f'  Best Model:       {os.path.join(config["save"]["checkpoint_dir"], "best_model.pth")}')
    logger.info(f'  Checkpoints:      {config["save"]["checkpoint_dir"]}')
    logger.info(f'  Logs:             {config["save"]["log_dir"]}')
    logger.info(f'  TensorBoard:      {tensorboard_dir}')
    logger.info('=' * 60)
    logger.info('ğŸš€ Next Steps:')
    logger.info(f'  1. View TensorBoard: tensorboard --logdir={tensorboard_dir}')
    logger.info(f'  2. Test best model:  python test_rgbb_tiny.py --checkpoint {os.path.join(config["save"]["checkpoint_dir"], "best_model.pth")}')
    logger.info('=' * 60)


if __name__ == '__main__':
    main()