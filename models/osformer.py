"""
TLCFormer / OSFormer: Temporal-Local-Contrast Transformer for Infrared Video Small Object Detection
å®Œæ•´æ¨¡å‹å®ç°ï¼Œé›†æˆæ‰€æœ‰æ¨¡å—

æ ¸å¿ƒæ”¹è¿›ï¼ˆç›¸æ¯”åŸ OSFormerï¼‰ï¼š
1. MADA (Motion-Aware Difference Attention): æ›¿ä»£ Doppler Filterï¼Œä½¿ç”¨å¸§å·®è€Œé FFT
2. DLCM (Deep Local Contrast Module): å±€éƒ¨å¯¹æ¯”åº¦å¢å¼ºï¼Œåˆ©ç”¨å°ç›®æ ‡çš„å±€éƒ¨æå€¼ç‰¹æ€§
3. Hybrid Energy-Preserving Mixer: åœ¨ VPA ä¸­ä½¿ç”¨ Max-Mean æ··åˆæ± åŒ–

ç‰©ç†å…ˆéªŒï¼š
- åˆ©ç”¨ |I_t - I_{t-1}| å¯¹æŠ—äº‘å±‚/èƒŒæ™¯æ‚æ³¢ï¼ˆèƒŒæ™¯ä¸åŠ¨ï¼Œç›®æ ‡åŠ¨ï¼‰
- åˆ©ç”¨ L_max / L_mean å¯¹æŠ—ä½ä¿¡å™ªæ¯”ï¼ˆç›®æ ‡æ˜¯å±€éƒ¨æå€¼ï¼‰
- åˆ©ç”¨ MaxPool å¯¹æŠ—ä¸‹é‡‡æ ·èƒ½é‡æŸå¤±ï¼ˆé˜²æ­¢ç½‘ç»œå±‚çº§åŠ æ·±æ—¶ç›®æ ‡æ¶ˆå¤±ï¼‰
"""

import torch
import torch.nn as nn
from typing import List, Dict, Tuple, Optional

from .cube_encoding import CubeEncoding
from .vpa import VariedSizePatchAttention
from .mada import MotionAwareDifferenceAttention
from .dlcm import DeepLocalContrastModule, DLCMForCube
from .neck import FeatureRefinementNeck
from .seq_head import SequenceRegressionHead

# ä¿ç•™ Doppler Filter ä»¥æ”¯æŒå‘åå…¼å®¹
try:
    from .doppler_filter import DopplerAdaptiveFilter
except ImportError:
    DopplerAdaptiveFilter = None


class OSFormer(nn.Module):
    """
    TLCFormer / OSFormer ä¸»æ¨¡å‹
    
    æ¶æ„æµç¨‹ï¼š
    1. Cube Encoding: å°†è§†é¢‘åºåˆ—ç¼–ç ä¸º 4D cube (B, C, H, W, S)
    2. MADA: è¿åŠ¨æ„ŸçŸ¥å·®åˆ†æ³¨æ„åŠ›ï¼ˆæ›¿ä»£ Doppler Filterï¼‰
    3. DLCM: æ·±åº¦å±€éƒ¨å¯¹æ¯”åº¦å¢å¼ºï¼ˆå¯é€‰ï¼‰
    4. VPA Encoder: å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆä½¿ç”¨ Hybrid Mixerï¼‰
    5. Feature Refinement Neck: ç‰¹å¾ç²¾ç‚¼ä¸èƒŒæ™¯æŠ‘åˆ¶
    6. Sequence Head: å¤šå¸§æ£€æµ‹å’Œè½¨è¿¹å…³è”
    
    å‚æ•°ï¼š
        num_frames (int): è¾“å…¥è§†é¢‘å¸§æ•° T
        sample_frames (int): é‡‡æ ·å¸§æ•° S
        img_size (int): å›¾åƒå°ºå¯¸
        num_classes (int): ç±»åˆ«æ•°
        embed_dim (int): VPA åµŒå…¥ç»´åº¦
        depths (List[int]): VPA å„é˜¶æ®µæ·±åº¦
        use_mada (bool): æ˜¯å¦ä½¿ç”¨ MADAï¼ˆæ›¿ä»£ Dopplerï¼‰
        use_dlcm (bool): æ˜¯å¦ä½¿ç”¨ DLCM
        use_doppler (bool): æ˜¯å¦ä½¿ç”¨æ—§ç‰ˆ Doppler Filterï¼ˆå‘åå…¼å®¹ï¼‰
        anchor_free (bool): æ˜¯å¦ä½¿ç”¨ anchor-free æ£€æµ‹
        mada_alpha (float): MADA ç¼©æ”¾å› å­
        dlcm_beta (float): DLCM èåˆæƒé‡
    """
    
    def __init__(
        self,
        num_frames: int = 5,
        sample_frames: int = 3,
        img_size: int = 640,
        num_classes: int = 1,
        embed_dim: int = 96,
        depths: List[int] = [2, 2, 6, 2],
        use_mada: bool = True,
        use_dlcm: bool = True,
        use_doppler: bool = False,  # é»˜è®¤ç¦ç”¨æ—§ç‰ˆ Doppler
        anchor_free: bool = True,
        dropout: float = 0.1,
        mada_alpha: float = 0.5,
        dlcm_beta: float = 0.5
    ):
        super().__init__()
        self.num_frames = num_frames
        self.sample_frames = sample_frames
        self.img_size = img_size
        self.num_classes = num_classes
        self.use_mada = use_mada
        self.use_dlcm = use_dlcm
        self.use_doppler = use_doppler and not use_mada  # MADA ä¼˜å…ˆäº Doppler
        
        # 1. Cube Encoding æ¨¡å—
        self.cube_encoder = CubeEncoding(
            num_frames=num_frames,
            sample_frames=sample_frames,
            img_size=img_size,
            normalize=True
        )
        
        # 2. MADA: Motion-Aware Difference Attentionï¼ˆæ›¿ä»£ Dopplerï¼‰
        if use_mada:
            self.mada = MotionAwareDifferenceAttention(
                num_frames=sample_frames,
                in_channels=2,  # ç°åº¦ + çƒ­çº¢å¤–
                alpha=mada_alpha
            )
        
        # 3. DLCM: Deep Local Contrast Module
        if use_dlcm:
            self.dlcm = DLCMForCube(
                in_channels=2,
                kernel_inner=3,
                kernel_outer=9,
                use_soft_contrast=False,
                beta=dlcm_beta
            )
        
        # å‘åå…¼å®¹ï¼šæ—§ç‰ˆ Doppler Adaptive Filter
        if self.use_doppler and DopplerAdaptiveFilter is not None:
            self.doppler_filter = DopplerAdaptiveFilter(
                img_size=img_size,
                num_frames=sample_frames,
                learn_filter=True,
                filter_type='adaptive'
            )
        
        # 3. Varied-Size Patch Attention
        # è¾“å…¥é€šé“æ•° = cube é€šé“æ•° (2) * é‡‡æ ·å¸§æ•° (S)
        in_channels = 2 * sample_frames
        
        self.vpa_encoder = VariedSizePatchAttention(
            in_channels=in_channels,
            embed_dim=embed_dim,
            depths=depths,
            img_size=img_size,
            patch_size=4,
            drop_rate=dropout
        )
        
        # è®¡ç®—å¤šå°ºåº¦ç‰¹å¾çš„é€šé“æ•°
        # å‡è®¾ depths = [2, 2, 6, 2]ï¼Œåˆ™é€šé“æ•°ä¸º [96, 192, 384, 768]
        num_stages = len(depths)
        feature_dims = [embed_dim * (2 ** i) for i in range(num_stages)]
        
        # 4. Feature Refinement Neck (æŒ‰è®ºæ–‡æ·»åŠ )
        neck_out_channels = 256
        self.neck = FeatureRefinementNeck(
            in_channels_list=feature_dims,  # [96, 192, 384, 768]
            out_channels=neck_out_channels,
            use_background_suppression=True
        )
        
        # 5. Sequence Regression Head
        # ä½¿ç”¨ Neck è¾“å‡ºçš„ F0 ç‰¹å¾
        self.seq_head = SequenceRegressionHead(
            in_channels=neck_out_channels,  # 256
            num_classes=num_classes,
            num_frames=num_frames,
            anchor_free=anchor_free
        )
        
        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)
    
    def _init_weights(self, m):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
        if isinstance(m, nn.Linear):
            nn.init.trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.Conv2d):
            nn.init.kaiming_normal_(m.weight, mode='fan_out')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)
    
    def forward(
        self,
        rgb_frames: torch.Tensor,
        thermal_frames: torch.Tensor
    ) -> List[Dict[str, torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­ï¼ˆTLCFormer æ”¹è¿›æµç¨‹ï¼‰
        
        å‚æ•°ï¼š
            rgb_frames: (B, T, 3, H, W) RGB è§†é¢‘åºåˆ—
            thermal_frames: (B, T, 1, H, W) çƒ­çº¢å¤–è§†é¢‘åºåˆ—
            
        è¿”å›ï¼š
            outputs: List of dictï¼Œé•¿åº¦ä¸º Tï¼ˆå¸§æ•°ï¼‰
                æ¯ä¸ª dict åŒ…å«ï¼š
                - 'cls': (B, num_classes, H', W') åˆ†ç±»é¢„æµ‹
                - 'bbox': (B, 4, H', W') è¾¹ç•Œæ¡†é¢„æµ‹
                - 'centerness': (B, 1, H', W') ä¸­å¿ƒåº¦ï¼ˆå¦‚æœ anchor_freeï¼‰
                - 'offset': (B, 2, H', W') è·¨å¸§åç§»ï¼ˆé™¤æœ€åä¸€å¸§ï¼‰
        """
        # 1. Cube Encoding
        cube = self.cube_encoder(rgb_frames, thermal_frames)  # (B, 2, H, W, S)
        
        # 2. MADA: è¿åŠ¨æ„ŸçŸ¥å·®åˆ†æ³¨æ„åŠ›ï¼ˆæ›¿ä»£ Doppler Filterï¼‰
        if self.use_mada:
            cube = self.mada(cube)  # (B, 2, H, W, S)
        elif self.use_doppler and hasattr(self, 'doppler_filter'):
            # å‘åå…¼å®¹ï¼šæ—§ç‰ˆ Doppler Filter
            cube = self.doppler_filter(cube)  # (B, 2, H, W, S)
        
        # 3. DLCM: æ·±åº¦å±€éƒ¨å¯¹æ¯”åº¦å¢å¼º
        if self.use_dlcm:
            cube = self.dlcm(cube)  # (B, 2, H, W, S)
        
        # 4. VPA Encoder - å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆä½¿ç”¨ Hybrid Mixerï¼‰
        features = self.vpa_encoder(cube)  # List of (B, C_i, H_i, W_i): [F1, F2, F3, F4]
        
        # 5. Feature Refinement Neck - ç‰¹å¾ç²¾ç‚¼ + èƒŒæ™¯æŠ‘åˆ¶
        F0 = self.neck(features)  # (B, 256, H/16, W/16)
        
        # 6. Sequence Regression Head - æ£€æµ‹å¤´
        outputs = self.seq_head(F0)  # List of dict
        
        return outputs
    
    def get_loss(
        self,
        outputs: List[Dict[str, torch.Tensor]],
        targets: List[Dict[str, torch.Tensor]],
        loss_weights: Dict[str, float] = None
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—æŸå¤±
        
        å‚æ•°ï¼š
            outputs: æ¨¡å‹è¾“å‡º
            targets: çœŸå®æ ‡ç­¾
            loss_weights: å„æŸå¤±é¡¹æƒé‡
            
        è¿”å›ï¼š
            total_loss: æ€»æŸå¤±
            loss_dict: å„æŸå¤±é¡¹å­—å…¸
        """
        if loss_weights is None:
            loss_weights = {
                'cls': 1.0,
                'bbox': 5.0,
                'centerness': 1.0,
                'offset': 2.0
            }
        
        # å¯¼å…¥æŸå¤±å‡½æ•°
        from ..utils.loss import compute_loss
        
        total_loss, loss_dict = compute_loss(
            outputs, targets, loss_weights
        )
        
        return total_loss, loss_dict


class OSFormerConfig:
    """TLCFormer / OSFormer é…ç½®ç±»"""
    
    def __init__(self, **kwargs):
        # æ¨¡å‹é…ç½®
        self.num_frames = kwargs.get('num_frames', 5)
        self.sample_frames = kwargs.get('sample_frames', 3)
        self.img_size = kwargs.get('img_size', 640)
        self.num_classes = kwargs.get('num_classes', 1)
        self.embed_dim = kwargs.get('embed_dim', 96)
        self.depths = kwargs.get('depths', [2, 2, 6, 2])
        
        # TLCFormer æ–°å¢é…ç½®
        self.use_mada = kwargs.get('use_mada', True)  # ä½¿ç”¨ MADA æ›¿ä»£ Doppler
        self.use_dlcm = kwargs.get('use_dlcm', True)  # ä½¿ç”¨ DLCM
        self.use_doppler = kwargs.get('use_doppler', False)  # æ—§ç‰ˆ Dopplerï¼ˆå‘åå…¼å®¹ï¼‰
        self.mada_alpha = kwargs.get('mada_alpha', 0.5)  # MADA ç¼©æ”¾å› å­
        self.dlcm_beta = kwargs.get('dlcm_beta', 0.5)  # DLCM èåˆæƒé‡
        
        self.anchor_free = kwargs.get('anchor_free', True)
        self.dropout = kwargs.get('dropout', 0.1)
        
        # è®­ç»ƒé…ç½®
        self.lr = kwargs.get('lr', 1e-3)
        self.weight_decay = kwargs.get('weight_decay', 0.05)
        self.batch_size = kwargs.get('batch_size', 8)
        self.num_epochs = kwargs.get('num_epochs', 50)
        
        # æŸå¤±æƒé‡
        self.loss_weights = kwargs.get('loss_weights', {
            'cls': 1.0,
            'bbox': 5.0,
            'centerness': 1.0,
            'offset': 2.0
        })
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'num_frames': self.num_frames,
            'sample_frames': self.sample_frames,
            'img_size': self.img_size,
            'num_classes': self.num_classes,
            'embed_dim': self.embed_dim,
            'depths': self.depths,
            'use_mada': self.use_mada,
            'use_dlcm': self.use_dlcm,
            'use_doppler': self.use_doppler,
            'mada_alpha': self.mada_alpha,
            'dlcm_beta': self.dlcm_beta,
            'anchor_free': self.anchor_free,
            'dropout': self.dropout,
            'lr': self.lr,
            'weight_decay': self.weight_decay,
            'batch_size': self.batch_size,
            'num_epochs': self.num_epochs,
            'loss_weights': self.loss_weights
        }
    
    @classmethod
    def from_dict(cls, config_dict):
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        return cls(**config_dict)


# TLCFormer åˆ«åï¼ˆå‘åå…¼å®¹ï¼‰
TLCFormerConfig = OSFormerConfig


def build_osformer(config: OSFormerConfig = None, **kwargs) -> OSFormer:
    """
    æ„å»º TLCFormer / OSFormer æ¨¡å‹
    
    å‚æ•°ï¼š
        config: æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        **kwargs: ç›´æ¥ä¼ é€’çš„é…ç½®å‚æ•°ï¼ˆå¦‚æœ config ä¸º Noneï¼‰
        
    è¿”å›ï¼š
        model: OSFormer æ¨¡å‹
    """
    if config is None:
        # å¦‚æœæ²¡æœ‰æä¾› configï¼Œä» kwargs åˆ›å»º
        if kwargs:
            config = OSFormerConfig(**kwargs)
        else:
            config = OSFormerConfig()
    
    model = OSFormer(
        num_frames=config.num_frames,
        sample_frames=config.sample_frames,
        img_size=config.img_size,
        num_classes=config.num_classes,
        embed_dim=config.embed_dim,
        depths=config.depths,
        use_mada=config.use_mada,
        use_dlcm=config.use_dlcm,
        use_doppler=config.use_doppler,
        anchor_free=config.anchor_free,
        dropout=config.dropout,
        mada_alpha=config.mada_alpha,
        dlcm_beta=config.dlcm_beta
    )
    
    return model


# åˆ«åï¼ˆå‘åå…¼å®¹å’Œæ–°å‘½åï¼‰
build_tlcformer = build_osformer
TLCFormer = OSFormer


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 60)
    print("Testing TLCFormer (OSFormer with MADA + DLCM + Hybrid Mixer)")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®ï¼ˆä½¿ç”¨æ–°çš„ TLCFormer ç‰¹æ€§ï¼‰
    config = OSFormerConfig(
        num_frames=5,
        sample_frames=3,
        img_size=640,
        num_classes=7,  # RGBT-Tiny æœ‰ 7 ä¸ªç±»åˆ«
        embed_dim=96,
        depths=[2, 2, 6, 2],
        use_mada=True,   # å¯ç”¨ MADA
        use_dlcm=True,   # å¯ç”¨ DLCM
        use_doppler=False,  # ç¦ç”¨æ—§ç‰ˆ Doppler
        mada_alpha=0.5,
        dlcm_beta=0.5
    )
    
    print("\næ¨¡å‹é…ç½®:")
    print(f"  use_mada: {config.use_mada}")
    print(f"  use_dlcm: {config.use_dlcm}")
    print(f"  use_doppler: {config.use_doppler}")
    print(f"  mada_alpha: {config.mada_alpha}")
    print(f"  dlcm_beta: {config.dlcm_beta}")
    
    # æ„å»ºæ¨¡å‹
    model = build_osformer(config)
    
    # æ¨¡æ‹Ÿè¾“å…¥
    B, T, H, W = 2, 5, 640, 640
    rgb_frames = torch.randn(B, T, 3, H, W)
    thermal_frames = torch.randn(B, T, 1, H, W)
    
    print(f"\nè¾“å…¥:")
    print(f"  RGB: {rgb_frames.shape}")
    print(f"  Thermal: {thermal_frames.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(rgb_frames, thermal_frames)
    
    print(f"\nè¾“å‡ºï¼ˆæ¯å¸§é¢„æµ‹ï¼‰:")
    for t, output in enumerate(outputs):
        print(f"  Frame {t}:")
        for key, val in output.items():
            print(f"    {key}: {val.shape}")
    
    # è®¡ç®—å‚æ•°é‡
    num_params = sum(p.numel() for p in model.parameters())
    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {num_params / 1e6:.2f}M")
    print(f"  å¯è®­ç»ƒå‚æ•°: {num_trainable / 1e6:.2f}M")
    
    # éªŒè¯æ–°æ¨¡å—
    print("\næ ¸å¿ƒæ¨¡å—éªŒè¯:")
    print(f"  âœ“ MADA: {hasattr(model, 'mada')}")
    print(f"  âœ“ DLCM: {hasattr(model, 'dlcm')}")
    print(f"  âœ“ VPA (Hybrid Mixer): {hasattr(model, 'vpa_encoder')}")
    
    print("\nğŸ‰ TLCFormer æµ‹è¯•é€šè¿‡ï¼")
    print("\næ”¹è¿›æ€»ç»“:")
    print("  1. MADA: å¸§å·®è¿åŠ¨æ³¨æ„åŠ›ï¼Œæ›¿ä»£ FFT å¤šæ™®å‹’æ»¤æ³¢")
    print("  2. DLCM: å±€éƒ¨å¯¹æ¯”åº¦å¢å¼ºï¼Œåˆ©ç”¨å°ç›®æ ‡æå€¼ç‰¹æ€§")
    print("  3. Hybrid Mixer: Max-Mean æ··åˆæ± åŒ–ï¼Œä¿ç•™å°ç›®æ ‡èƒ½é‡")

